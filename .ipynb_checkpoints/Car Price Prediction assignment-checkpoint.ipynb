{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_HsWVrWvDNP"
   },
   "source": [
    "# Car Price Prediction::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Neq61yUOvDNV"
   },
   "source": [
    "Download dataset from this link:\n",
    "\n",
    "https://www.kaggle.com/hellbuoy/car-price-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "errs9eyZvDNW"
   },
   "source": [
    "# Problem Statement::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92PLZp2kwKxv",
    "outputId": "256b59cb-a3bf-4c09-a1f5-6cdb364a18d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount google drive in to your Colab enviornment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvDEDSF3yS1S",
    "outputId": "e83d5edf-d639-420f-b1bb-a53d87727c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/AI_assignment\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/AI_assignment/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCu6NRLVvDNX"
   },
   "source": [
    "A Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n",
    "\n",
    "They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n",
    "\n",
    "Which variables are significant in predicting the price of a car\n",
    "How well those variables describe the price of a car\n",
    "Based on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n",
    "\n",
    "# task::\n",
    "We are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-vI6CymvDNX"
   },
   "source": [
    "# WORKFLOW ::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRvlK8RBvDNX"
   },
   "source": [
    "1.Load Data\n",
    "\n",
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "\n",
    "3.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "\n",
    "4.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "\n",
    "5.Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
    "6.Train the Model with Epochs (100) and validate it\n",
    "\n",
    "7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
    "\n",
    "8.Evaluation Step\n",
    "\n",
    "9.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "duXMXXhZvDNY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "car_data = pd.read_csv('/content/drive/MyDrive/AI_assignment/CarPrice_Assignment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "vd2sfUEUPRvi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "hnf-BIvL5-qO",
    "outputId": "b6ad9a61-8203-49bc-fec8-9c7be751d992"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginetype</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero giulia</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero stelvio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero Quadrifoglio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>ohcv</td>\n",
       "      <td>six</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100 ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_ID  symboling                   CarName  ... citympg highwaympg    price\n",
       "0       1          3        alfa-romero giulia  ...      21         27  13495.0\n",
       "1       2          3       alfa-romero stelvio  ...      21         27  16500.0\n",
       "2       3          1  alfa-romero Quadrifoglio  ...      19         26  16500.0\n",
       "3       4          2               audi 100 ls  ...      24         30  13950.0\n",
       "4       5          2                audi 100ls  ...      18         22  17450.0\n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JRgNW0hzOVH",
    "outputId": "aaa30897-3839-4114-f131-5bc215e78773"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alfa-romero giulia', 'alfa-romero stelvio',\n",
       "       'alfa-romero Quadrifoglio', 'audi 100 ls', 'audi 100ls',\n",
       "       'audi fox', 'audi 5000', 'audi 4000', 'audi 5000s (diesel)',\n",
       "       'bmw 320i', 'bmw x1', 'bmw x3', 'bmw z4', 'bmw x4', 'bmw x5',\n",
       "       'chevrolet impala', 'chevrolet monte carlo', 'chevrolet vega 2300',\n",
       "       'dodge rampage', 'dodge challenger se', 'dodge d200',\n",
       "       'dodge monaco (sw)', 'dodge colt hardtop', 'dodge colt (sw)',\n",
       "       'dodge coronet custom', 'dodge dart custom',\n",
       "       'dodge coronet custom (sw)', 'honda civic', 'honda civic cvcc',\n",
       "       'honda accord cvcc', 'honda accord lx', 'honda civic 1500 gl',\n",
       "       'honda accord', 'honda civic 1300', 'honda prelude',\n",
       "       'honda civic (auto)', 'isuzu MU-X', 'isuzu D-Max ',\n",
       "       'isuzu D-Max V-Cross', 'jaguar xj', 'jaguar xf', 'jaguar xk',\n",
       "       'maxda rx3', 'maxda glc deluxe', 'mazda rx2 coupe', 'mazda rx-4',\n",
       "       'mazda glc deluxe', 'mazda 626', 'mazda glc', 'mazda rx-7 gs',\n",
       "       'mazda glc 4', 'mazda glc custom l', 'mazda glc custom',\n",
       "       'buick electra 225 custom', 'buick century luxus (sw)',\n",
       "       'buick century', 'buick skyhawk', 'buick opel isuzu deluxe',\n",
       "       'buick skylark', 'buick century special',\n",
       "       'buick regal sport coupe (turbo)', 'mercury cougar',\n",
       "       'mitsubishi mirage', 'mitsubishi lancer', 'mitsubishi outlander',\n",
       "       'mitsubishi g4', 'mitsubishi mirage g4', 'mitsubishi montero',\n",
       "       'mitsubishi pajero', 'Nissan versa', 'nissan gt-r', 'nissan rogue',\n",
       "       'nissan latio', 'nissan titan', 'nissan leaf', 'nissan juke',\n",
       "       'nissan note', 'nissan clipper', 'nissan nv200', 'nissan dayz',\n",
       "       'nissan fuga', 'nissan otti', 'nissan teana', 'nissan kicks',\n",
       "       'peugeot 504', 'peugeot 304', 'peugeot 504 (sw)', 'peugeot 604sl',\n",
       "       'peugeot 505s turbo diesel', 'plymouth fury iii',\n",
       "       'plymouth cricket', 'plymouth satellite custom (sw)',\n",
       "       'plymouth fury gran sedan', 'plymouth valiant', 'plymouth duster',\n",
       "       'porsche macan', 'porcshce panamera', 'porsche cayenne',\n",
       "       'porsche boxter', 'renault 12tl', 'renault 5 gtl', 'saab 99e',\n",
       "       'saab 99le', 'saab 99gle', 'subaru', 'subaru dl', 'subaru brz',\n",
       "       'subaru baja', 'subaru r1', 'subaru r2', 'subaru trezia',\n",
       "       'subaru tribeca', 'toyota corona mark ii', 'toyota corona',\n",
       "       'toyota corolla 1200', 'toyota corona hardtop',\n",
       "       'toyota corolla 1600 (sw)', 'toyota carina', 'toyota mark ii',\n",
       "       'toyota corolla', 'toyota corolla liftback',\n",
       "       'toyota celica gt liftback', 'toyota corolla tercel',\n",
       "       'toyota corona liftback', 'toyota starlet', 'toyota tercel',\n",
       "       'toyota cressida', 'toyota celica gt', 'toyouta tercel',\n",
       "       'vokswagen rabbit', 'volkswagen 1131 deluxe sedan',\n",
       "       'volkswagen model 111', 'volkswagen type 3', 'volkswagen 411 (sw)',\n",
       "       'volkswagen super beetle', 'volkswagen dasher', 'vw dasher',\n",
       "       'vw rabbit', 'volkswagen rabbit', 'volkswagen rabbit custom',\n",
       "       'volvo 145e (sw)', 'volvo 144ea', 'volvo 244dl', 'volvo 245',\n",
       "       'volvo 264gl', 'volvo diesel', 'volvo 246'], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data['CarName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6NTeH-qvDNa",
    "outputId": "22e54046-ac09-4239-a3bc-6e028aef24cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are empty cells, if there are then row and column indexes will be returned where values are empty or missing\n",
    "np.where(car_data.applymap(lambda x: x ==''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "euCqFI3Y0l6h",
    "outputId": "efbc7a1d-e172-4147-92d3-be20ab65e6a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID              False\n",
       "symboling           False\n",
       "CarName             False\n",
       "fueltype            False\n",
       "aspiration          False\n",
       "doornumber          False\n",
       "carbody             False\n",
       "drivewheel          False\n",
       "enginelocation      False\n",
       "wheelbase           False\n",
       "carlength           False\n",
       "carwidth            False\n",
       "carheight           False\n",
       "curbweight          False\n",
       "enginetype          False\n",
       "cylindernumber      False\n",
       "enginesize          False\n",
       "fuelsystem          False\n",
       "boreratio           False\n",
       "stroke              False\n",
       "compressionratio    False\n",
       "horsepower          False\n",
       "peakrpm             False\n",
       "citympg             False\n",
       "highwaympg          False\n",
       "price               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 162,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "UwZgj7IIvXRm"
   },
   "outputs": [],
   "source": [
    "# correct the name error in audi 100 ls\n",
    "car_data.iloc[3,2] = 'audi 100ls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1cCvWApvDNZ",
    "outputId": "4d480387-4142-46eb-fff8-6326e0c57795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID                int64\n",
       "symboling             int64\n",
       "CarName              object\n",
       "fueltype             object\n",
       "aspiration           object\n",
       "doornumber           object\n",
       "carbody              object\n",
       "drivewheel           object\n",
       "enginelocation       object\n",
       "wheelbase           float64\n",
       "carlength           float64\n",
       "carwidth            float64\n",
       "carheight           float64\n",
       "curbweight            int64\n",
       "enginetype           object\n",
       "cylindernumber       object\n",
       "enginesize            int64\n",
       "fuelsystem           object\n",
       "boreratio           float64\n",
       "stroke              float64\n",
       "compressionratio    float64\n",
       "horsepower            int64\n",
       "peakrpm               int64\n",
       "citympg               int64\n",
       "highwaympg            int64\n",
       "price               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "yCSHog6LFfdp"
   },
   "outputs": [],
   "source": [
    "car_data.drop(columns=['car_ID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BN6vZOZr5EpP",
    "outputId": "0a6ce9f1-1def-4f5b-f4b7-d0880a0b914e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symboling', 'CarName', 'fueltype', 'aspiration', 'doornumber',\n",
       "       'carbody', 'drivewheel', 'enginelocation', 'wheelbase', 'carlength',\n",
       "       'carwidth', 'carheight', 'curbweight', 'enginetype', 'cylindernumber',\n",
       "       'enginesize', 'fuelsystem', 'boreratio', 'stroke', 'compressionratio',\n",
       "       'horsepower', 'peakrpm', 'citympg', 'highwaympg', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get columns so that we can use the column names for onehot encoding of catagorical featrues in next cell\n",
    "car_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "nqvKX-JyvDNa"
   },
   "outputs": [],
   "source": [
    "# onehot encode all catagorical columns\n",
    "final_car = pd.get_dummies(car_data, columns=['CarName','symboling','fueltype',\t'aspiration',\t'doornumber',\t'carbody',\t'drivewheel',\t'enginelocation',\t'enginetype',\t'cylindernumber',\t'fuelsystem'], drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "VUW7m4p1C_Iz",
    "outputId": "f93de7f1-94a6-45b2-c548-7423bb04778c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>CarName_audi 100ls</th>\n",
       "      <th>CarName_audi 4000</th>\n",
       "      <th>CarName_audi 5000</th>\n",
       "      <th>CarName_audi 5000s (diesel)</th>\n",
       "      <th>CarName_audi fox</th>\n",
       "      <th>CarName_bmw 320i</th>\n",
       "      <th>CarName_bmw x1</th>\n",
       "      <th>CarName_bmw x3</th>\n",
       "      <th>CarName_bmw x4</th>\n",
       "      <th>CarName_bmw x5</th>\n",
       "      <th>CarName_bmw z4</th>\n",
       "      <th>CarName_buick century</th>\n",
       "      <th>CarName_buick century luxus (sw)</th>\n",
       "      <th>CarName_buick century special</th>\n",
       "      <th>CarName_buick electra 225 custom</th>\n",
       "      <th>CarName_buick opel isuzu deluxe</th>\n",
       "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
       "      <th>CarName_buick skyhawk</th>\n",
       "      <th>CarName_buick skylark</th>\n",
       "      <th>CarName_chevrolet impala</th>\n",
       "      <th>CarName_chevrolet monte carlo</th>\n",
       "      <th>CarName_chevrolet vega 2300</th>\n",
       "      <th>CarName_dodge challenger se</th>\n",
       "      <th>...</th>\n",
       "      <th>CarName_volvo 245</th>\n",
       "      <th>CarName_volvo 246</th>\n",
       "      <th>CarName_volvo 264gl</th>\n",
       "      <th>CarName_volvo diesel</th>\n",
       "      <th>CarName_vw dasher</th>\n",
       "      <th>CarName_vw rabbit</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>fueltype_gas</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "      <th>doornumber_two</th>\n",
       "      <th>carbody_hardtop</th>\n",
       "      <th>carbody_hatchback</th>\n",
       "      <th>carbody_sedan</th>\n",
       "      <th>carbody_wagon</th>\n",
       "      <th>drivewheel_fwd</th>\n",
       "      <th>drivewheel_rwd</th>\n",
       "      <th>enginelocation_rear</th>\n",
       "      <th>enginetype_dohcv</th>\n",
       "      <th>enginetype_l</th>\n",
       "      <th>enginetype_ohc</th>\n",
       "      <th>enginetype_ohcf</th>\n",
       "      <th>enginetype_ohcv</th>\n",
       "      <th>enginetype_rotor</th>\n",
       "      <th>cylindernumber_five</th>\n",
       "      <th>cylindernumber_four</th>\n",
       "      <th>cylindernumber_six</th>\n",
       "      <th>cylindernumber_three</th>\n",
       "      <th>cylindernumber_twelve</th>\n",
       "      <th>cylindernumber_two</th>\n",
       "      <th>fuelsystem_2bbl</th>\n",
       "      <th>fuelsystem_4bbl</th>\n",
       "      <th>fuelsystem_idi</th>\n",
       "      <th>fuelsystem_mfi</th>\n",
       "      <th>fuelsystem_mpfi</th>\n",
       "      <th>fuelsystem_spdi</th>\n",
       "      <th>fuelsystem_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wheelbase  carlength  ...  fuelsystem_spdi  fuelsystem_spfi\n",
       "0       88.6      168.8  ...                0                0\n",
       "1       88.6      168.8  ...                0                0\n",
       "2       94.5      171.2  ...                0                0\n",
       "3       99.8      176.6  ...                0                0\n",
       "4       99.4      176.6  ...                0                0\n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "hgIZc8J6UswW",
    "outputId": "17db7f3d-8ebf-46cf-cbba-b5b5c7557ca0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>CarName_audi 100ls</th>\n",
       "      <th>CarName_audi 4000</th>\n",
       "      <th>CarName_audi 5000</th>\n",
       "      <th>CarName_audi 5000s (diesel)</th>\n",
       "      <th>CarName_audi fox</th>\n",
       "      <th>CarName_bmw 320i</th>\n",
       "      <th>CarName_bmw x1</th>\n",
       "      <th>CarName_bmw x3</th>\n",
       "      <th>CarName_bmw x4</th>\n",
       "      <th>CarName_bmw x5</th>\n",
       "      <th>CarName_bmw z4</th>\n",
       "      <th>CarName_buick century</th>\n",
       "      <th>CarName_buick century luxus (sw)</th>\n",
       "      <th>CarName_buick century special</th>\n",
       "      <th>CarName_buick electra 225 custom</th>\n",
       "      <th>CarName_buick opel isuzu deluxe</th>\n",
       "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
       "      <th>CarName_buick skyhawk</th>\n",
       "      <th>CarName_buick skylark</th>\n",
       "      <th>CarName_chevrolet impala</th>\n",
       "      <th>CarName_chevrolet monte carlo</th>\n",
       "      <th>CarName_chevrolet vega 2300</th>\n",
       "      <th>CarName_dodge challenger se</th>\n",
       "      <th>...</th>\n",
       "      <th>CarName_volvo 245</th>\n",
       "      <th>CarName_volvo 246</th>\n",
       "      <th>CarName_volvo 264gl</th>\n",
       "      <th>CarName_volvo diesel</th>\n",
       "      <th>CarName_vw dasher</th>\n",
       "      <th>CarName_vw rabbit</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>fueltype_gas</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "      <th>doornumber_two</th>\n",
       "      <th>carbody_hardtop</th>\n",
       "      <th>carbody_hatchback</th>\n",
       "      <th>carbody_sedan</th>\n",
       "      <th>carbody_wagon</th>\n",
       "      <th>drivewheel_fwd</th>\n",
       "      <th>drivewheel_rwd</th>\n",
       "      <th>enginelocation_rear</th>\n",
       "      <th>enginetype_dohcv</th>\n",
       "      <th>enginetype_l</th>\n",
       "      <th>enginetype_ohc</th>\n",
       "      <th>enginetype_ohcf</th>\n",
       "      <th>enginetype_ohcv</th>\n",
       "      <th>enginetype_rotor</th>\n",
       "      <th>cylindernumber_five</th>\n",
       "      <th>cylindernumber_four</th>\n",
       "      <th>cylindernumber_six</th>\n",
       "      <th>cylindernumber_three</th>\n",
       "      <th>cylindernumber_twelve</th>\n",
       "      <th>cylindernumber_two</th>\n",
       "      <th>fuelsystem_2bbl</th>\n",
       "      <th>fuelsystem_4bbl</th>\n",
       "      <th>fuelsystem_idi</th>\n",
       "      <th>fuelsystem_mfi</th>\n",
       "      <th>fuelsystem_mpfi</th>\n",
       "      <th>fuelsystem_spdi</th>\n",
       "      <th>fuelsystem_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.756585</td>\n",
       "      <td>174.049268</td>\n",
       "      <td>65.907805</td>\n",
       "      <td>53.724878</td>\n",
       "      <td>2555.565854</td>\n",
       "      <td>126.907317</td>\n",
       "      <td>3.329756</td>\n",
       "      <td>3.255415</td>\n",
       "      <td>10.142537</td>\n",
       "      <td>104.117073</td>\n",
       "      <td>5125.121951</td>\n",
       "      <td>25.219512</td>\n",
       "      <td>30.751220</td>\n",
       "      <td>13276.710571</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.107317</td>\n",
       "      <td>0.326829</td>\n",
       "      <td>0.263415</td>\n",
       "      <td>0.156098</td>\n",
       "      <td>0.131707</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.180488</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.370732</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.058537</td>\n",
       "      <td>0.721951</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.063415</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.053659</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.117073</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.321951</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.043902</td>\n",
       "      <td>0.004878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.021776</td>\n",
       "      <td>12.337289</td>\n",
       "      <td>2.145204</td>\n",
       "      <td>2.443522</td>\n",
       "      <td>520.680204</td>\n",
       "      <td>41.642693</td>\n",
       "      <td>0.270844</td>\n",
       "      <td>0.313597</td>\n",
       "      <td>3.972040</td>\n",
       "      <td>39.544167</td>\n",
       "      <td>476.985643</td>\n",
       "      <td>6.542142</td>\n",
       "      <td>6.886443</td>\n",
       "      <td>7988.852332</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.098531</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.098531</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.098531</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.310274</td>\n",
       "      <td>0.470202</td>\n",
       "      <td>0.441564</td>\n",
       "      <td>0.363836</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.297446</td>\n",
       "      <td>0.385535</td>\n",
       "      <td>0.497483</td>\n",
       "      <td>0.194127</td>\n",
       "      <td>0.475361</td>\n",
       "      <td>0.500215</td>\n",
       "      <td>0.328031</td>\n",
       "      <td>0.493865</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.235330</td>\n",
       "      <td>0.449134</td>\n",
       "      <td>0.261054</td>\n",
       "      <td>0.244304</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>0.225894</td>\n",
       "      <td>0.418201</td>\n",
       "      <td>0.322294</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>0.468368</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.297446</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.499498</td>\n",
       "      <td>0.205380</td>\n",
       "      <td>0.069843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>86.600000</td>\n",
       "      <td>141.100000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>47.800000</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5118.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>94.500000</td>\n",
       "      <td>166.300000</td>\n",
       "      <td>64.100000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2145.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7788.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>173.200000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>2414.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>3.290000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10295.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>102.400000</td>\n",
       "      <td>183.100000</td>\n",
       "      <td>66.900000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2935.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>16503.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.900000</td>\n",
       "      <td>208.100000</td>\n",
       "      <td>72.300000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>45400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wheelbase   carlength  ...  fuelsystem_spdi  fuelsystem_spfi\n",
       "count  205.000000  205.000000  ...       205.000000       205.000000\n",
       "mean    98.756585  174.049268  ...         0.043902         0.004878\n",
       "std      6.021776   12.337289  ...         0.205380         0.069843\n",
       "min     86.600000  141.100000  ...         0.000000         0.000000\n",
       "25%     94.500000  166.300000  ...         0.000000         0.000000\n",
       "50%     97.000000  173.200000  ...         0.000000         0.000000\n",
       "75%    102.400000  183.100000  ...         0.000000         0.000000\n",
       "max    120.900000  208.100000  ...         1.000000         1.000000\n",
       "\n",
       "[8 rows x 193 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check statistical data to see abnormal values and outliers\n",
    "final_car.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "q_sikuUQAGD4"
   },
   "outputs": [],
   "source": [
    "#initialize a seed value so that each time we can get the same random number sequence, it will help us  as a team\n",
    "# working on a common project to work on the same random data. Each new seed will generate a particular sequnce\n",
    "#of random number. You can choose any seed value here of your choice\n",
    "# 0.72 means we have taken 72% values for training set as we will make 72/4 = 18 rows of k fold validation data, where\n",
    "# value of k will be 4 when we compile and fit our model for validation\n",
    "np.random.seed(11111)\n",
    "msk = np.random.rand(len(final_car)) < 0.72\n",
    "train_total = final_car[msk]\n",
    "test_total = final_car[~msk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSjX5UckTu1_",
    "outputId": "178c3bdb-a34e-4502-b1e7-3508270965b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "#check the length of our test and train datasets\n",
    "print(len(train_total))\n",
    "print(len(test_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "a4njPsfOfLJP",
    "outputId": "e5f50d61-f5c1-4d7d-f40c-a7ee06beddef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>CarName_audi 100ls</th>\n",
       "      <th>CarName_audi 4000</th>\n",
       "      <th>CarName_audi 5000</th>\n",
       "      <th>CarName_audi 5000s (diesel)</th>\n",
       "      <th>CarName_audi fox</th>\n",
       "      <th>CarName_bmw 320i</th>\n",
       "      <th>CarName_bmw x1</th>\n",
       "      <th>CarName_bmw x3</th>\n",
       "      <th>CarName_bmw x4</th>\n",
       "      <th>CarName_bmw x5</th>\n",
       "      <th>CarName_bmw z4</th>\n",
       "      <th>CarName_buick century</th>\n",
       "      <th>CarName_buick century luxus (sw)</th>\n",
       "      <th>CarName_buick century special</th>\n",
       "      <th>CarName_buick electra 225 custom</th>\n",
       "      <th>CarName_buick opel isuzu deluxe</th>\n",
       "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
       "      <th>CarName_buick skyhawk</th>\n",
       "      <th>CarName_buick skylark</th>\n",
       "      <th>CarName_chevrolet impala</th>\n",
       "      <th>CarName_chevrolet monte carlo</th>\n",
       "      <th>CarName_chevrolet vega 2300</th>\n",
       "      <th>CarName_dodge challenger se</th>\n",
       "      <th>...</th>\n",
       "      <th>CarName_volvo 245</th>\n",
       "      <th>CarName_volvo 246</th>\n",
       "      <th>CarName_volvo 264gl</th>\n",
       "      <th>CarName_volvo diesel</th>\n",
       "      <th>CarName_vw dasher</th>\n",
       "      <th>CarName_vw rabbit</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>fueltype_gas</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "      <th>doornumber_two</th>\n",
       "      <th>carbody_hardtop</th>\n",
       "      <th>carbody_hatchback</th>\n",
       "      <th>carbody_sedan</th>\n",
       "      <th>carbody_wagon</th>\n",
       "      <th>drivewheel_fwd</th>\n",
       "      <th>drivewheel_rwd</th>\n",
       "      <th>enginelocation_rear</th>\n",
       "      <th>enginetype_dohcv</th>\n",
       "      <th>enginetype_l</th>\n",
       "      <th>enginetype_ohc</th>\n",
       "      <th>enginetype_ohcf</th>\n",
       "      <th>enginetype_ohcv</th>\n",
       "      <th>enginetype_rotor</th>\n",
       "      <th>cylindernumber_five</th>\n",
       "      <th>cylindernumber_four</th>\n",
       "      <th>cylindernumber_six</th>\n",
       "      <th>cylindernumber_three</th>\n",
       "      <th>cylindernumber_twelve</th>\n",
       "      <th>cylindernumber_two</th>\n",
       "      <th>fuelsystem_2bbl</th>\n",
       "      <th>fuelsystem_4bbl</th>\n",
       "      <th>fuelsystem_idi</th>\n",
       "      <th>fuelsystem_mfi</th>\n",
       "      <th>fuelsystem_mpfi</th>\n",
       "      <th>fuelsystem_spdi</th>\n",
       "      <th>fuelsystem_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.8</td>\n",
       "      <td>177.3</td>\n",
       "      <td>66.3</td>\n",
       "      <td>53.1</td>\n",
       "      <td>2507</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>15250.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2844</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>17710.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2954</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>18920.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.9</td>\n",
       "      <td>3086</td>\n",
       "      <td>131</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.3</td>\n",
       "      <td>140</td>\n",
       "      <td>5500</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>23875.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99.5</td>\n",
       "      <td>178.2</td>\n",
       "      <td>67.9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3053</td>\n",
       "      <td>131</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.40</td>\n",
       "      <td>7.0</td>\n",
       "      <td>160</td>\n",
       "      <td>5500</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>17859.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2395</td>\n",
       "      <td>108</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.8</td>\n",
       "      <td>101</td>\n",
       "      <td>5800</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>16925.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    wheelbase  carlength  ...  fuelsystem_spdi  fuelsystem_spfi\n",
       "1        88.6      168.8  ...                0                0\n",
       "2        94.5      171.2  ...                0                0\n",
       "3        99.8      176.6  ...                0                0\n",
       "4        99.4      176.6  ...                0                0\n",
       "5        99.8      177.3  ...                0                0\n",
       "6       105.8      192.7  ...                0                0\n",
       "7       105.8      192.7  ...                0                0\n",
       "8       105.8      192.7  ...                0                0\n",
       "9        99.5      178.2  ...                0                0\n",
       "11      101.2      176.8  ...                0                0\n",
       "\n",
       "[10 rows x 193 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "BeYOhn1Eiams",
    "outputId": "692801ab-7caa-487d-970a-ce41e76e3563"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>CarName_audi 100ls</th>\n",
       "      <th>CarName_audi 4000</th>\n",
       "      <th>CarName_audi 5000</th>\n",
       "      <th>CarName_audi 5000s (diesel)</th>\n",
       "      <th>CarName_audi fox</th>\n",
       "      <th>CarName_bmw 320i</th>\n",
       "      <th>CarName_bmw x1</th>\n",
       "      <th>CarName_bmw x3</th>\n",
       "      <th>CarName_bmw x4</th>\n",
       "      <th>CarName_bmw x5</th>\n",
       "      <th>CarName_bmw z4</th>\n",
       "      <th>CarName_buick century</th>\n",
       "      <th>CarName_buick century luxus (sw)</th>\n",
       "      <th>CarName_buick century special</th>\n",
       "      <th>CarName_buick electra 225 custom</th>\n",
       "      <th>CarName_buick opel isuzu deluxe</th>\n",
       "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
       "      <th>CarName_buick skyhawk</th>\n",
       "      <th>CarName_buick skylark</th>\n",
       "      <th>CarName_chevrolet impala</th>\n",
       "      <th>CarName_chevrolet monte carlo</th>\n",
       "      <th>CarName_chevrolet vega 2300</th>\n",
       "      <th>CarName_dodge challenger se</th>\n",
       "      <th>...</th>\n",
       "      <th>CarName_volvo 245</th>\n",
       "      <th>CarName_volvo 246</th>\n",
       "      <th>CarName_volvo 264gl</th>\n",
       "      <th>CarName_volvo diesel</th>\n",
       "      <th>CarName_vw dasher</th>\n",
       "      <th>CarName_vw rabbit</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>fueltype_gas</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "      <th>doornumber_two</th>\n",
       "      <th>carbody_hardtop</th>\n",
       "      <th>carbody_hatchback</th>\n",
       "      <th>carbody_sedan</th>\n",
       "      <th>carbody_wagon</th>\n",
       "      <th>drivewheel_fwd</th>\n",
       "      <th>drivewheel_rwd</th>\n",
       "      <th>enginelocation_rear</th>\n",
       "      <th>enginetype_dohcv</th>\n",
       "      <th>enginetype_l</th>\n",
       "      <th>enginetype_ohc</th>\n",
       "      <th>enginetype_ohcf</th>\n",
       "      <th>enginetype_ohcv</th>\n",
       "      <th>enginetype_rotor</th>\n",
       "      <th>cylindernumber_five</th>\n",
       "      <th>cylindernumber_four</th>\n",
       "      <th>cylindernumber_six</th>\n",
       "      <th>cylindernumber_three</th>\n",
       "      <th>cylindernumber_twelve</th>\n",
       "      <th>cylindernumber_two</th>\n",
       "      <th>fuelsystem_2bbl</th>\n",
       "      <th>fuelsystem_4bbl</th>\n",
       "      <th>fuelsystem_idi</th>\n",
       "      <th>fuelsystem_mfi</th>\n",
       "      <th>fuelsystem_mpfi</th>\n",
       "      <th>fuelsystem_spdi</th>\n",
       "      <th>fuelsystem_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.00000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.692199</td>\n",
       "      <td>173.658156</td>\n",
       "      <td>65.875887</td>\n",
       "      <td>53.648227</td>\n",
       "      <td>2546.787234</td>\n",
       "      <td>125.666667</td>\n",
       "      <td>3.324184</td>\n",
       "      <td>3.256809</td>\n",
       "      <td>10.070355</td>\n",
       "      <td>103.702128</td>\n",
       "      <td>5143.971631</td>\n",
       "      <td>25.113475</td>\n",
       "      <td>30.581560</td>\n",
       "      <td>13379.132390</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.304965</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.156028</td>\n",
       "      <td>0.141844</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.347518</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.581560</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.092199</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.035461</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.005665</td>\n",
       "      <td>12.320089</td>\n",
       "      <td>2.188604</td>\n",
       "      <td>2.508204</td>\n",
       "      <td>529.769152</td>\n",
       "      <td>41.733451</td>\n",
       "      <td>0.266123</td>\n",
       "      <td>0.296387</td>\n",
       "      <td>3.868579</td>\n",
       "      <td>38.424275</td>\n",
       "      <td>474.472458</td>\n",
       "      <td>6.509435</td>\n",
       "      <td>6.734937</td>\n",
       "      <td>8189.494568</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.144819</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.118672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.326785</td>\n",
       "      <td>0.462034</td>\n",
       "      <td>0.448910</td>\n",
       "      <td>0.364176</td>\n",
       "      <td>0.350134</td>\n",
       "      <td>0.290337</td>\n",
       "      <td>0.400354</td>\n",
       "      <td>0.498935</td>\n",
       "      <td>0.202567</td>\n",
       "      <td>0.477879</td>\n",
       "      <td>0.498935</td>\n",
       "      <td>0.33490</td>\n",
       "      <td>0.495062</td>\n",
       "      <td>0.482206</td>\n",
       "      <td>0.118672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217986</td>\n",
       "      <td>0.448910</td>\n",
       "      <td>0.269150</td>\n",
       "      <td>0.232165</td>\n",
       "      <td>0.166616</td>\n",
       "      <td>0.245321</td>\n",
       "      <td>0.424908</td>\n",
       "      <td>0.326785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.166616</td>\n",
       "      <td>0.470508</td>\n",
       "      <td>0.144819</td>\n",
       "      <td>0.290337</td>\n",
       "      <td>0.084215</td>\n",
       "      <td>0.499645</td>\n",
       "      <td>0.185601</td>\n",
       "      <td>0.084215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>86.600000</td>\n",
       "      <td>144.600000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>47.800000</td>\n",
       "      <td>1713.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5118.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>94.500000</td>\n",
       "      <td>166.300000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>51.600000</td>\n",
       "      <td>2128.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7689.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>96.500000</td>\n",
       "      <td>172.400000</td>\n",
       "      <td>65.400000</td>\n",
       "      <td>53.900000</td>\n",
       "      <td>2410.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>3.290000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10245.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>102.400000</td>\n",
       "      <td>180.300000</td>\n",
       "      <td>66.600000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2952.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>16695.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>115.600000</td>\n",
       "      <td>202.600000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>45400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wheelbase   carlength  ...  fuelsystem_spdi  fuelsystem_spfi\n",
       "count  141.000000  141.000000  ...       141.000000       141.000000\n",
       "mean    98.692199  173.658156  ...         0.035461         0.007092\n",
       "std      6.005665   12.320089  ...         0.185601         0.084215\n",
       "min     86.600000  144.600000  ...         0.000000         0.000000\n",
       "25%     94.500000  166.300000  ...         0.000000         0.000000\n",
       "50%     96.500000  172.400000  ...         0.000000         0.000000\n",
       "75%    102.400000  180.300000  ...         0.000000         0.000000\n",
       "max    115.600000  202.600000  ...         1.000000         1.000000\n",
       "\n",
       "[8 rows x 193 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check statistical overview if there are some outliers and abnormal values\n",
    "train_total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iwv0k5MXkjiU",
    "outputId": "88cc1ac0-d8d8-480c-cb7c-87e3eae13574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheelbase          float64\n",
      "carlength          float64\n",
      "carwidth           float64\n",
      "carheight          float64\n",
      "curbweight           int64\n",
      "                    ...   \n",
      "fuelsystem_idi       uint8\n",
      "fuelsystem_mfi       uint8\n",
      "fuelsystem_mpfi      uint8\n",
      "fuelsystem_spdi      uint8\n",
      "fuelsystem_spfi      uint8\n",
      "Length: 193, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_total.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "UMVbWuxTzEUh"
   },
   "outputs": [],
   "source": [
    "# get our price labels and store in another dataframe\n",
    "train_label = train_total.loc[:,'price']\n",
    "test_label = test_total.loc[:,'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ok93gWC0V7RC",
    "outputId": "97581347-076b-4283-b1e3-61786533265c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      16500.0\n",
       "2      16500.0\n",
       "3      13950.0\n",
       "4      17450.0\n",
       "5      15250.0\n",
       "        ...   \n",
       "200    16845.0\n",
       "201    19045.0\n",
       "202    21485.0\n",
       "203    22470.0\n",
       "204    22625.0\n",
       "Name: price, Length: 141, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "0pj0hGliz6ld"
   },
   "outputs": [],
   "source": [
    "# drop price from oroginal training and test dataset , as price is not needed there\n",
    "test_data= test_total.drop(columns = ['price'])\n",
    "train_data= train_total.drop(columns = ['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uw8yz0e1RjS",
    "outputId": "98132e77-f91e-454e-d555-07d8c2c546a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 192)"
      ]
     },
     "execution_count": 178,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "ic0-eZgDZjsV",
    "outputId": "637fe0ec-53e7-4298-96d8-33417af3e19e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>CarName_audi 100ls</th>\n",
       "      <th>CarName_audi 4000</th>\n",
       "      <th>CarName_audi 5000</th>\n",
       "      <th>CarName_audi 5000s (diesel)</th>\n",
       "      <th>CarName_audi fox</th>\n",
       "      <th>CarName_bmw 320i</th>\n",
       "      <th>CarName_bmw x1</th>\n",
       "      <th>CarName_bmw x3</th>\n",
       "      <th>CarName_bmw x4</th>\n",
       "      <th>CarName_bmw x5</th>\n",
       "      <th>CarName_bmw z4</th>\n",
       "      <th>CarName_buick century</th>\n",
       "      <th>CarName_buick century luxus (sw)</th>\n",
       "      <th>CarName_buick century special</th>\n",
       "      <th>CarName_buick electra 225 custom</th>\n",
       "      <th>CarName_buick opel isuzu deluxe</th>\n",
       "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
       "      <th>CarName_buick skyhawk</th>\n",
       "      <th>CarName_buick skylark</th>\n",
       "      <th>CarName_chevrolet impala</th>\n",
       "      <th>CarName_chevrolet monte carlo</th>\n",
       "      <th>CarName_chevrolet vega 2300</th>\n",
       "      <th>CarName_dodge challenger se</th>\n",
       "      <th>CarName_dodge colt (sw)</th>\n",
       "      <th>...</th>\n",
       "      <th>CarName_volvo 245</th>\n",
       "      <th>CarName_volvo 246</th>\n",
       "      <th>CarName_volvo 264gl</th>\n",
       "      <th>CarName_volvo diesel</th>\n",
       "      <th>CarName_vw dasher</th>\n",
       "      <th>CarName_vw rabbit</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>fueltype_gas</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "      <th>doornumber_two</th>\n",
       "      <th>carbody_hardtop</th>\n",
       "      <th>carbody_hatchback</th>\n",
       "      <th>carbody_sedan</th>\n",
       "      <th>carbody_wagon</th>\n",
       "      <th>drivewheel_fwd</th>\n",
       "      <th>drivewheel_rwd</th>\n",
       "      <th>enginelocation_rear</th>\n",
       "      <th>enginetype_dohcv</th>\n",
       "      <th>enginetype_l</th>\n",
       "      <th>enginetype_ohc</th>\n",
       "      <th>enginetype_ohcf</th>\n",
       "      <th>enginetype_ohcv</th>\n",
       "      <th>enginetype_rotor</th>\n",
       "      <th>cylindernumber_five</th>\n",
       "      <th>cylindernumber_four</th>\n",
       "      <th>cylindernumber_six</th>\n",
       "      <th>cylindernumber_three</th>\n",
       "      <th>cylindernumber_twelve</th>\n",
       "      <th>cylindernumber_two</th>\n",
       "      <th>fuelsystem_2bbl</th>\n",
       "      <th>fuelsystem_4bbl</th>\n",
       "      <th>fuelsystem_idi</th>\n",
       "      <th>fuelsystem_mfi</th>\n",
       "      <th>fuelsystem_mpfi</th>\n",
       "      <th>fuelsystem_spdi</th>\n",
       "      <th>fuelsystem_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.8</td>\n",
       "      <td>177.3</td>\n",
       "      <td>66.3</td>\n",
       "      <td>53.1</td>\n",
       "      <td>2507</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>2952</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.8</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3049</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>8.7</td>\n",
       "      <td>160</td>\n",
       "      <td>5300</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3012</td>\n",
       "      <td>173</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.8</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3217</td>\n",
       "      <td>145</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3062</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     wheelbase  carlength  ...  fuelsystem_spdi  fuelsystem_spfi\n",
       "1         88.6      168.8  ...                0                0\n",
       "2         94.5      171.2  ...                0                0\n",
       "3         99.8      176.6  ...                0                0\n",
       "4         99.4      176.6  ...                0                0\n",
       "5         99.8      177.3  ...                0                0\n",
       "..         ...        ...  ...              ...              ...\n",
       "200      109.1      188.8  ...                0                0\n",
       "201      109.1      188.8  ...                0                0\n",
       "202      109.1      188.8  ...                0                0\n",
       "203      109.1      188.8  ...                0                0\n",
       "204      109.1      188.8  ...                0                0\n",
       "\n",
       "[141 rows x 192 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTXSdXZs5InD",
    "outputId": "8a478a65-7b1b-4202-b516-581f968b5507"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'wheelbase',\n",
       " 1: 'carlength',\n",
       " 2: 'carwidth',\n",
       " 3: 'carheight',\n",
       " 4: 'curbweight',\n",
       " 5: 'enginesize',\n",
       " 6: 'boreratio',\n",
       " 7: 'stroke',\n",
       " 8: 'compressionratio',\n",
       " 9: 'horsepower',\n",
       " 10: 'peakrpm',\n",
       " 11: 'citympg',\n",
       " 12: 'highwaympg',\n",
       " 13: 'CarName_alfa-romero Quadrifoglio',\n",
       " 14: 'CarName_alfa-romero giulia',\n",
       " 15: 'CarName_alfa-romero stelvio',\n",
       " 16: 'CarName_audi 100ls',\n",
       " 17: 'CarName_audi 4000',\n",
       " 18: 'CarName_audi 5000',\n",
       " 19: 'CarName_audi 5000s (diesel)',\n",
       " 20: 'CarName_audi fox',\n",
       " 21: 'CarName_bmw 320i',\n",
       " 22: 'CarName_bmw x1',\n",
       " 23: 'CarName_bmw x3',\n",
       " 24: 'CarName_bmw x4',\n",
       " 25: 'CarName_bmw x5',\n",
       " 26: 'CarName_bmw z4',\n",
       " 27: 'CarName_buick century',\n",
       " 28: 'CarName_buick century luxus (sw)',\n",
       " 29: 'CarName_buick century special',\n",
       " 30: 'CarName_buick electra 225 custom',\n",
       " 31: 'CarName_buick opel isuzu deluxe',\n",
       " 32: 'CarName_buick regal sport coupe (turbo)',\n",
       " 33: 'CarName_buick skyhawk',\n",
       " 34: 'CarName_buick skylark',\n",
       " 35: 'CarName_chevrolet impala',\n",
       " 36: 'CarName_chevrolet monte carlo',\n",
       " 37: 'CarName_chevrolet vega 2300',\n",
       " 38: 'CarName_dodge challenger se',\n",
       " 39: 'CarName_dodge colt (sw)',\n",
       " 40: 'CarName_dodge colt hardtop',\n",
       " 41: 'CarName_dodge coronet custom',\n",
       " 42: 'CarName_dodge coronet custom (sw)',\n",
       " 43: 'CarName_dodge d200',\n",
       " 44: 'CarName_dodge dart custom',\n",
       " 45: 'CarName_dodge monaco (sw)',\n",
       " 46: 'CarName_dodge rampage',\n",
       " 47: 'CarName_honda accord',\n",
       " 48: 'CarName_honda accord cvcc',\n",
       " 49: 'CarName_honda accord lx',\n",
       " 50: 'CarName_honda civic',\n",
       " 51: 'CarName_honda civic (auto)',\n",
       " 52: 'CarName_honda civic 1300',\n",
       " 53: 'CarName_honda civic 1500 gl',\n",
       " 54: 'CarName_honda civic cvcc',\n",
       " 55: 'CarName_honda prelude',\n",
       " 56: 'CarName_isuzu D-Max ',\n",
       " 57: 'CarName_isuzu D-Max V-Cross',\n",
       " 58: 'CarName_isuzu MU-X',\n",
       " 59: 'CarName_jaguar xf',\n",
       " 60: 'CarName_jaguar xj',\n",
       " 61: 'CarName_jaguar xk',\n",
       " 62: 'CarName_maxda glc deluxe',\n",
       " 63: 'CarName_maxda rx3',\n",
       " 64: 'CarName_mazda 626',\n",
       " 65: 'CarName_mazda glc',\n",
       " 66: 'CarName_mazda glc 4',\n",
       " 67: 'CarName_mazda glc custom',\n",
       " 68: 'CarName_mazda glc custom l',\n",
       " 69: 'CarName_mazda glc deluxe',\n",
       " 70: 'CarName_mazda rx-4',\n",
       " 71: 'CarName_mazda rx-7 gs',\n",
       " 72: 'CarName_mazda rx2 coupe',\n",
       " 73: 'CarName_mercury cougar',\n",
       " 74: 'CarName_mitsubishi g4',\n",
       " 75: 'CarName_mitsubishi lancer',\n",
       " 76: 'CarName_mitsubishi mirage',\n",
       " 77: 'CarName_mitsubishi mirage g4',\n",
       " 78: 'CarName_mitsubishi montero',\n",
       " 79: 'CarName_mitsubishi outlander',\n",
       " 80: 'CarName_mitsubishi pajero',\n",
       " 81: 'CarName_nissan clipper',\n",
       " 82: 'CarName_nissan dayz',\n",
       " 83: 'CarName_nissan fuga',\n",
       " 84: 'CarName_nissan gt-r',\n",
       " 85: 'CarName_nissan juke',\n",
       " 86: 'CarName_nissan kicks',\n",
       " 87: 'CarName_nissan latio',\n",
       " 88: 'CarName_nissan leaf',\n",
       " 89: 'CarName_nissan note',\n",
       " 90: 'CarName_nissan nv200',\n",
       " 91: 'CarName_nissan otti',\n",
       " 92: 'CarName_nissan rogue',\n",
       " 93: 'CarName_nissan teana',\n",
       " 94: 'CarName_nissan titan',\n",
       " 95: 'CarName_peugeot 304',\n",
       " 96: 'CarName_peugeot 504',\n",
       " 97: 'CarName_peugeot 504 (sw)',\n",
       " 98: 'CarName_peugeot 505s turbo diesel',\n",
       " 99: 'CarName_peugeot 604sl',\n",
       " 100: 'CarName_plymouth cricket',\n",
       " 101: 'CarName_plymouth duster',\n",
       " 102: 'CarName_plymouth fury gran sedan',\n",
       " 103: 'CarName_plymouth fury iii',\n",
       " 104: 'CarName_plymouth satellite custom (sw)',\n",
       " 105: 'CarName_plymouth valiant',\n",
       " 106: 'CarName_porcshce panamera',\n",
       " 107: 'CarName_porsche boxter',\n",
       " 108: 'CarName_porsche cayenne',\n",
       " 109: 'CarName_porsche macan',\n",
       " 110: 'CarName_renault 12tl',\n",
       " 111: 'CarName_renault 5 gtl',\n",
       " 112: 'CarName_saab 99e',\n",
       " 113: 'CarName_saab 99gle',\n",
       " 114: 'CarName_saab 99le',\n",
       " 115: 'CarName_subaru',\n",
       " 116: 'CarName_subaru baja',\n",
       " 117: 'CarName_subaru brz',\n",
       " 118: 'CarName_subaru dl',\n",
       " 119: 'CarName_subaru r1',\n",
       " 120: 'CarName_subaru r2',\n",
       " 121: 'CarName_subaru trezia',\n",
       " 122: 'CarName_subaru tribeca',\n",
       " 123: 'CarName_toyota carina',\n",
       " 124: 'CarName_toyota celica gt',\n",
       " 125: 'CarName_toyota celica gt liftback',\n",
       " 126: 'CarName_toyota corolla',\n",
       " 127: 'CarName_toyota corolla 1200',\n",
       " 128: 'CarName_toyota corolla 1600 (sw)',\n",
       " 129: 'CarName_toyota corolla liftback',\n",
       " 130: 'CarName_toyota corolla tercel',\n",
       " 131: 'CarName_toyota corona',\n",
       " 132: 'CarName_toyota corona hardtop',\n",
       " 133: 'CarName_toyota corona liftback',\n",
       " 134: 'CarName_toyota corona mark ii',\n",
       " 135: 'CarName_toyota cressida',\n",
       " 136: 'CarName_toyota mark ii',\n",
       " 137: 'CarName_toyota starlet',\n",
       " 138: 'CarName_toyota tercel',\n",
       " 139: 'CarName_toyouta tercel',\n",
       " 140: 'CarName_vokswagen rabbit',\n",
       " 141: 'CarName_volkswagen 1131 deluxe sedan',\n",
       " 142: 'CarName_volkswagen 411 (sw)',\n",
       " 143: 'CarName_volkswagen dasher',\n",
       " 144: 'CarName_volkswagen model 111',\n",
       " 145: 'CarName_volkswagen rabbit',\n",
       " 146: 'CarName_volkswagen rabbit custom',\n",
       " 147: 'CarName_volkswagen super beetle',\n",
       " 148: 'CarName_volkswagen type 3',\n",
       " 149: 'CarName_volvo 144ea',\n",
       " 150: 'CarName_volvo 145e (sw)',\n",
       " 151: 'CarName_volvo 244dl',\n",
       " 152: 'CarName_volvo 245',\n",
       " 153: 'CarName_volvo 246',\n",
       " 154: 'CarName_volvo 264gl',\n",
       " 155: 'CarName_volvo diesel',\n",
       " 156: 'CarName_vw dasher',\n",
       " 157: 'CarName_vw rabbit',\n",
       " 158: 'symboling_-1',\n",
       " 159: 'symboling_0',\n",
       " 160: 'symboling_1',\n",
       " 161: 'symboling_2',\n",
       " 162: 'symboling_3',\n",
       " 163: 'fueltype_gas',\n",
       " 164: 'aspiration_turbo',\n",
       " 165: 'doornumber_two',\n",
       " 166: 'carbody_hardtop',\n",
       " 167: 'carbody_hatchback',\n",
       " 168: 'carbody_sedan',\n",
       " 169: 'carbody_wagon',\n",
       " 170: 'drivewheel_fwd',\n",
       " 171: 'drivewheel_rwd',\n",
       " 172: 'enginelocation_rear',\n",
       " 173: 'enginetype_dohcv',\n",
       " 174: 'enginetype_l',\n",
       " 175: 'enginetype_ohc',\n",
       " 176: 'enginetype_ohcf',\n",
       " 177: 'enginetype_ohcv',\n",
       " 178: 'enginetype_rotor',\n",
       " 179: 'cylindernumber_five',\n",
       " 180: 'cylindernumber_four',\n",
       " 181: 'cylindernumber_six',\n",
       " 182: 'cylindernumber_three',\n",
       " 183: 'cylindernumber_twelve',\n",
       " 184: 'cylindernumber_two',\n",
       " 185: 'fuelsystem_2bbl',\n",
       " 186: 'fuelsystem_4bbl',\n",
       " 187: 'fuelsystem_idi',\n",
       " 188: 'fuelsystem_mfi',\n",
       " 189: 'fuelsystem_mpfi',\n",
       " 190: 'fuelsystem_spdi',\n",
       " 191: 'fuelsystem_spfi'}"
      ]
     },
     "execution_count": 180,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get indices of the columns so that we can know how many columns we have to normalize, as catagorical columns which we\n",
    "# have added with onehot encoding, do not need to be normalized.. normalizing will be done in next cell\n",
    "{train_data.columns.get_loc(c): c for idx, c in enumerate(train_data.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "CTvnqjLaFSYr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "1h5vhggTyRyw"
   },
   "outputs": [],
   "source": [
    "## we normalize data because data has big vlaues in decimal and it will worsen performance of our model, may overfit \n",
    "## or  we may face hardware resource high usage\n",
    "# we will apply the formula normalized_train_data = (train_data - mean)/ stadrad_deviation\n",
    "## firt take mean of training, then subtract mean from each value of the array slice train_data.iloc[:,0:13]\n",
    "mean = train_data.iloc[:,0:13].mean(axis=0) # taking the mean of \n",
    "train_data.iloc[:,0:13] -= mean\n",
    "std = train_data.iloc[:,0:13].std(axis=0)\n",
    "train_data.iloc[:,0:13] /= std\n",
    "test_data.iloc[:,0:13] -= mean\n",
    "test_data.iloc[:,0:13] /= std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdXge3xhAyiN",
    "outputId": "e3e1a79a-2b05-495c-91a2-4d94e2329518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wheelbase             98.692199\n",
       "carlength            173.658156\n",
       "carwidth              65.875887\n",
       "carheight             53.648227\n",
       "curbweight          2546.787234\n",
       "enginesize           125.666667\n",
       "boreratio              3.324184\n",
       "stroke                 3.256809\n",
       "compressionratio      10.070355\n",
       "horsepower           103.702128\n",
       "peakrpm             5143.971631\n",
       "citympg               25.113475\n",
       "highwaympg            30.581560\n",
       "dtype: float64"
      ]
     },
     "execution_count": 182,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dKIOrdXIEDr",
    "outputId": "09c7d66a-5ab9-426f-9bbf-f5ca8c31e199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wheelbase             6.005665\n",
       "carlength            12.320089\n",
       "carwidth              2.188604\n",
       "carheight             2.508204\n",
       "curbweight          529.769152\n",
       "enginesize           41.733451\n",
       "boreratio             0.266123\n",
       "stroke                0.296387\n",
       "compressionratio      3.868579\n",
       "horsepower           38.424275\n",
       "peakrpm             474.472458\n",
       "citympg               6.509435\n",
       "highwaympg            6.734937\n",
       "dtype: float64"
      ]
     },
     "execution_count": 183,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "CZYfOs0cfaGE"
   },
   "outputs": [],
   "source": [
    "mean_label = train_label.mean()\n",
    "train_label -= mean_label\n",
    "std_label = train_label.std()\n",
    "train_label /= std_label\n",
    "test_label -= mean_label\n",
    "test_label /= std_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UwH-6fJG4RB",
    "outputId": "f37b4cdd-5c0a-4102-acdf-c710b6679aec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13379.132390070921"
      ]
     },
     "execution_count": 185,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0HkwMimH-9W",
    "outputId": "93cf8400-5552-46d4-c5ec-dfb9476a02be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8189.4945680106175"
      ]
     },
     "execution_count": 186,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mc7B1amLmsx",
    "outputId": "8e9985fe-9470-46f4-e150-65d597726601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13379.132390070921\n"
     ]
    }
   ],
   "source": [
    "print(mean_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8uIRUHEw7g4",
    "outputId": "4abdb45d-c6ca-446c-d674-43b868d0e9ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.014148\n",
       "10     0.372534\n",
       "14     1.365880\n",
       "15     2.122337\n",
       "18    -1.004718\n",
       "         ...   \n",
       "192    0.056886\n",
       "193   -0.132991\n",
       "194   -0.053621\n",
       "196    0.318196\n",
       "198    0.615529\n",
       "Name: price, Length: 64, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZwYKROqCyWwi",
    "outputId": "d9f2017a-1793-4d72-b22d-22e059810a1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 192)"
      ]
     },
     "execution_count": 189,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "ejyRo91P9Klh"
   },
   "outputs": [],
   "source": [
    "#store in numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "eLTpt0qn-R5y"
   },
   "outputs": [],
   "source": [
    "test = np.array(test_data.iloc[:]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "6ym52Tun-vhn"
   },
   "outputs": [],
   "source": [
    "train = np.array(train_data.iloc[:]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "TnFGfxGn_d1b"
   },
   "outputs": [],
   "source": [
    "test_l= np.array(test_label.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "kklQZ0za_qZb"
   },
   "outputs": [],
   "source": [
    "train_l= np.array(train_label.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVbXDcGe5cY2",
    "outputId": "79f6cf2c-a5ae-44bf-e8cd-57e3a8fd811f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 195,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArLkQAzx9W0f",
    "outputId": "13d9d83f-fe2f-4250-ba53-53cfb235036a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 196,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(141,192)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS0mDY0d9y3Q",
    "outputId": "a49598a3-7696-4847-bc0a-90dcd664efb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 197,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm416iVz953_"
   },
   "source": [
    "\n",
    "# Models section\n",
    "```\n",
    "#WE will configure different models here according to relu, tanh , regularization, dropout etc..\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "EqOJjh8n8fMU"
   },
   "outputs": [],
   "source": [
    "# we are passing activation function as a parameter here so that we can call this function with tanh or relu while\n",
    "# fitting and training the model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model(act):\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(128, activation= act,input_shape=(train.shape[1],)))\n",
    "  model.add(layers.Dense(64, activation= act))\n",
    "  model.add(layers.Dense(32, activation= act))\n",
    "  model.add(layers.Dense(1))\n",
    "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKs2Axd19Rsx",
    "outputId": "8cdb4563-3513-4d70-be95-cab84b1d663b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_192 (Dense)            (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 35,073\n",
      "Trainable params: 35,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model('relu').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShTLMMUPWE2E",
    "outputId": "2ecfba3b-9b92-446f-8754-6835b089f62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_196 (Dense)            (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 35,073\n",
      "Trainable params: 35,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model('tanh').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "iLNbzXjKqGSw"
   },
   "outputs": [],
   "source": [
    "# Regularized model\n",
    "from keras import regularizers\n",
    "def build_model_regular(act):\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(10, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001),input_shape=(train.shape[1],)))\n",
    "  model.add(layers.Dense(8, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "  model.add(layers.Dense(6, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "  model.add(layers.Dense(1))\n",
    "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afnNh94NrncJ",
    "outputId": "bebc621d-155c-47ae-d1d4-6f7def305f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_200 (Dense)            (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 2,079\n",
      "Trainable params: 2,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model_regular('tanh').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "hKOI8TLD1SHd"
   },
   "outputs": [],
   "source": [
    "# dropout model\n",
    "from keras import regularizers\n",
    "def build_model_drop(act):\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(10, activation= act,input_shape=(train.shape[1],)))\n",
    "  model.add(layers.Dropout(0.2))\n",
    "  model.add(layers.Dense(8, activation= act))\n",
    "  model.add(layers.Dropout(0.2))\n",
    "  model.add(layers.Dense(6, activation= act))\n",
    "  model.add(layers.Dropout(0.2))\n",
    "  model.add(layers.Dense(1))\n",
    "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_3icFwvKuGy",
    "outputId": "d656902f-2070-49fb-8e13-54edbcdf2da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 2,079\n",
      "Trainable params: 2,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model_drop('relu').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwAm7RMr_eMa"
   },
   "source": [
    "# K Fold validation section\n",
    "## here we will use len(train)//k to make 141//4 = 36 rows for validation in each validation test and collect the validation scores for relu , tanh , regularization , and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTizsf6znpb7",
    "outputId": "261835b1-9c40-46ac-a474-0d48fac97940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b6a51830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 1\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6ad8c9e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 2\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b5c0d7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 3\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6bc68b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#k fold validation with relu\n",
    "# 141/4\n",
    "import numpy as np\n",
    "k =  4\n",
    "num_val_samples = len(train) // k\n",
    "num_epochs = 100\n",
    "all_scores_relu = []\n",
    "for i in range(k):\n",
    "  print('processing fold #', i)\n",
    "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
    "  # print(partial_train_data)\n",
    "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
    "  model = build_model('relu')\n",
    "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "  all_scores_relu.append(val_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HaXgBohaz4WI",
    "outputId": "8857bde4-60de-45f9-a826-116725f0a32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6ad967200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 1\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6ad95e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 2\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b0da15f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 3\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b5e677a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# 141/4\n",
    "#k fold validation with tanh\n",
    "import numpy as np\n",
    "k =  4\n",
    "num_val_samples = len(train) // k\n",
    "num_epochs = 100\n",
    "all_scores_tanh = []\n",
    "for i in range(k):\n",
    "  print('processing fold #', i)\n",
    "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
    "  # print(partial_train_data)\n",
    "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
    "  model = build_model('tanh')\n",
    "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "  all_scores_tanh.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SD6TuagJb54U",
    "outputId": "550972d4-a37d-4875-c384-ad21aa82413c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6bceec9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 1\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b9ed39e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 2\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b9ed3e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 3\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b694a170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#k-fold validtion with regularization\n",
    "import numpy as np\n",
    "k =  4\n",
    "num_val_samples = len(train) // k\n",
    "num_epochs = 100\n",
    "all_scores_regular = []\n",
    "for i in range(k):\n",
    "  print('processing fold #', i)\n",
    "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
    "  # print(partial_train_data)\n",
    "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
    "  model = build_model_regular('relu')\n",
    "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "  all_scores_regular.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3ENBDAMrHtb",
    "outputId": "721753a6-a2ff-4f04-be56-2d8ad89f5d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 947us/step - loss: 0.7836 - mae: 0.6582\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6849 - mae: 0.5250\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 921us/step - loss: 0.6058 - mae: 0.5574\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 982us/step - loss: 0.5037 - mae: 0.4585\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4986 - mae: 0.4664\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 949us/step - loss: 0.5802 - mae: 0.4604\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6526 - mae: 0.4818\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6838 - mae: 0.5564\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 943us/step - loss: 0.5513 - mae: 0.4783\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 980us/step - loss: 0.4993 - mae: 0.4620\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6288 - mae: 0.4943\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5745 - mae: 0.4684\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6083 - mae: 0.5045\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 932us/step - loss: 0.5550 - mae: 0.4650\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 952us/step - loss: 0.4322 - mae: 0.4399\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6446 - mae: 0.4739\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5703 - mae: 0.4729\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6759 - mae: 0.5032\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 986us/step - loss: 0.7300 - mae: 0.5691\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8043 - mae: 0.5372\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7026 - mae: 0.4759\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8208 - mae: 0.5759\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4222 - mae: 0.3816\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.1579 - mae: 0.6315\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4417 - mae: 0.4089\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 978us/step - loss: 0.4890 - mae: 0.4332\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7226 - mae: 0.5326\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6143 - mae: 0.4987\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4138 - mae: 0.4102\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4967 - mae: 0.4612\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7271 - mae: 0.5731\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6570 - mae: 0.5116\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4299 - mae: 0.4191\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 954us/step - loss: 0.2726 - mae: 0.3146\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4069 - mae: 0.4186\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4201 - mae: 0.4341\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6433 - mae: 0.5459\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7927 - mae: 0.5560\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3818 - mae: 0.4084\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3813 - mae: 0.4453\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7214 - mae: 0.5017\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5816 - mae: 0.4539\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4720 - mae: 0.4660\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8166 - mae: 0.5538\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5622 - mae: 0.4971\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5483 - mae: 0.4592\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4533 - mae: 0.4296\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8482 - mae: 0.5362\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5704 - mae: 0.4759\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4364 - mae: 0.4100\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3213 - mae: 0.3866\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8501 - mae: 0.6023\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3460 - mae: 0.3882\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4423 - mae: 0.4329\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6833 - mae: 0.5442\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5850 - mae: 0.4994\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5518 - mae: 0.4368\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3823 - mae: 0.3822\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5088 - mae: 0.4555\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5841 - mae: 0.4894\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4261 - mae: 0.4626\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2992 - mae: 0.3754\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3994 - mae: 0.4166\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.9888 - mae: 0.6181\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5080 - mae: 0.5402\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7800 - mae: 0.5571\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4285 - mae: 0.4197\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3553 - mae: 0.4081\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3108 - mae: 0.3673\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6916 - mae: 0.5162\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6785 - mae: 0.5436\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8392 - mae: 0.5913\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4354 - mae: 0.3701\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3992 - mae: 0.4087\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4589 - mae: 0.4695\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7036 - mae: 0.5384\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3091 - mae: 0.3595\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6585 - mae: 0.4815\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4584 - mae: 0.4205\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6009 - mae: 0.5008\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6869 - mae: 0.5404\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4147 - mae: 0.4151\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2889 - mae: 0.3819\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3252 - mae: 0.3645\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3831 - mae: 0.3914\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4420 - mae: 0.4326\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4524 - mae: 0.4243\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2966 - mae: 0.3695\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6347 - mae: 0.5159\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4784 - mae: 0.4622\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4603 - mae: 0.4700\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5507 - mae: 0.4505\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5105 - mae: 0.4381\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4366 - mae: 0.3788\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5224 - mae: 0.4497\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6998 - mae: 0.4765\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2603 - mae: 0.3723\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4073 - mae: 0.4223\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4181 - mae: 0.4403\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4341 - mae: 0.4109\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b5b94f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5670 - mae: 0.5407\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 939us/step - loss: 0.6963 - mae: 0.6958\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6472 - mae: 0.6106\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7655 - mae: 0.6030\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3168 - mae: 0.3985\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5973 - mae: 0.4642\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4877 - mae: 0.4668\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3978 - mae: 0.4601\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4482 - mae: 0.4828\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 947us/step - loss: 0.5066 - mae: 0.4305\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5122 - mae: 0.4565\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2272 - mae: 0.3540\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3009 - mae: 0.3903\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2408 - mae: 0.3489\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2597 - mae: 0.4077\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4109 - mae: 0.4200\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2205 - mae: 0.3216\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2145 - mae: 0.3084\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2265 - mae: 0.3690\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2154 - mae: 0.3549\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3479 - mae: 0.3806\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1651 - mae: 0.2705\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2699 - mae: 0.3502\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3751 - mae: 0.3508\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2220 - mae: 0.3051\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3299 - mae: 0.3594\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2492 - mae: 0.3187\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4365 - mae: 0.3623\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2388 - mae: 0.3255\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3041 - mae: 0.3750\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2259 - mae: 0.2713\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2377 - mae: 0.3241\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4768 - mae: 0.3679\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2897 - mae: 0.3391\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2937 - mae: 0.3122\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2910 - mae: 0.3334\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1220 - mae: 0.2531\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2557 - mae: 0.3366\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1994 - mae: 0.3327\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2427 - mae: 0.2670\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1152 - mae: 0.2580\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1841 - mae: 0.2980\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2665 - mae: 0.3537\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4163 - mae: 0.4014\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2351 - mae: 0.3391\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1441 - mae: 0.3016\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2870 - mae: 0.3495\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2668 - mae: 0.3206\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1463 - mae: 0.2725\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1358 - mae: 0.2607\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1954 - mae: 0.2863\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2326 - mae: 0.3258\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1082 - mae: 0.2462\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1724 - mae: 0.2974\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2682 - mae: 0.3303\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1232 - mae: 0.2633\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3354 - mae: 0.3700\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2118 - mae: 0.2788\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1165 - mae: 0.2606\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1916 - mae: 0.3047\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1341 - mae: 0.2314\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1687 - mae: 0.2758\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1965 - mae: 0.3120\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1497 - mae: 0.2576\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1432 - mae: 0.2803\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2288 - mae: 0.3206\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1585 - mae: 0.2637\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1893 - mae: 0.2557\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2387 - mae: 0.3299\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2283 - mae: 0.2550\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0932 - mae: 0.2318\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1384 - mae: 0.2345\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3347 - mae: 0.3513\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3278 - mae: 0.3653\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5472 - mae: 0.3610\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1792 - mae: 0.2584\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1089 - mae: 0.2267\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1518 - mae: 0.2778\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2906 - mae: 0.3068\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1466 - mae: 0.2941\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1305 - mae: 0.2619\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2306 - mae: 0.2688\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2762 - mae: 0.3163\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3421 - mae: 0.3590\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2097 - mae: 0.3267\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2286 - mae: 0.3050\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0886 - mae: 0.2225\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2160 - mae: 0.2937\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1050 - mae: 0.2301\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2398 - mae: 0.3202\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1159 - mae: 0.2325\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1077 - mae: 0.2052\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1256 - mae: 0.2453\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3999 - mae: 0.3738\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1119 - mae: 0.1871\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1213 - mae: 0.2241\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1552 - mae: 0.2500\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1118 - mae: 0.2203\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1024 - mae: 0.2354\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0948 - mae: 0.2242\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1631 - mae: 0.2744\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6bc5fe4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4772 - mae: 0.4202\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 1ms/step - loss: 1.0295 - mae: 0.7556\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 949us/step - loss: 0.7407 - mae: 0.5959\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4980 - mae: 0.4636\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.0514 - mae: 0.6216\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8827 - mae: 0.5496\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4272 - mae: 0.4347\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4891 - mae: 0.4636\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4305 - mae: 0.4593\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5227 - mae: 0.4828\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5784 - mae: 0.4648\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4708 - mae: 0.4657\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3848 - mae: 0.4355\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2897 - mae: 0.3963\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3589 - mae: 0.3947\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7231 - mae: 0.5122\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6635 - mae: 0.5232\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2633 - mae: 0.3182\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4941 - mae: 0.4577\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8865 - mae: 0.5924\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2646 - mae: 0.3712\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2756 - mae: 0.4071\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4156 - mae: 0.3603\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3127 - mae: 0.3607\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4678 - mae: 0.4372\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3799 - mae: 0.3881\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3122 - mae: 0.3743\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4596 - mae: 0.4375\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2424 - mae: 0.3193\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7215 - mae: 0.4467\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2602 - mae: 0.3171\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1560 - mae: 0.2874\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7326 - mae: 0.4746\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3597 - mae: 0.3904\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3391 - mae: 0.3632\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4067 - mae: 0.3315\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4118 - mae: 0.3761\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2880 - mae: 0.3502\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1886 - mae: 0.3011\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3301 - mae: 0.3608\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5451 - mae: 0.4176\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3544 - mae: 0.4040\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1974 - mae: 0.2850\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2163 - mae: 0.3122\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2028 - mae: 0.3320\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1997 - mae: 0.2884\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1986 - mae: 0.2923\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2511 - mae: 0.3033\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2502 - mae: 0.3272\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4437 - mae: 0.3946\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3096 - mae: 0.3511\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2325 - mae: 0.3416\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3370 - mae: 0.3594\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4298 - mae: 0.3142\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6553 - mae: 0.4779\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3015 - mae: 0.3358\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2292 - mae: 0.3224\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1221 - mae: 0.2592\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5715 - mae: 0.4204\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4014 - mae: 0.3791\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1202 - mae: 0.2537\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3960 - mae: 0.4005\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4465 - mae: 0.3931\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2266 - mae: 0.3041\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4336 - mae: 0.3873\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3199 - mae: 0.3412\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3334 - mae: 0.3844\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2516 - mae: 0.3117\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1913 - mae: 0.2791\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3408 - mae: 0.3641\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4673 - mae: 0.4206\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3511 - mae: 0.3582\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2478 - mae: 0.2800\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2495 - mae: 0.3398\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1528 - mae: 0.2758\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1451 - mae: 0.2717\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2552 - mae: 0.2977\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1548 - mae: 0.2888\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2912 - mae: 0.3193\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1644 - mae: 0.3026\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1873 - mae: 0.2576\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1482 - mae: 0.2499\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1956 - mae: 0.2709\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.9151 - mae: 0.4600\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3341 - mae: 0.2988\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1329 - mae: 0.2511\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3164 - mae: 0.3013\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1950 - mae: 0.2831\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4189 - mae: 0.3931\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4194 - mae: 0.3281\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2013 - mae: 0.2734\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2522 - mae: 0.2914\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5704 - mae: 0.3916\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5827 - mae: 0.3976\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2654 - mae: 0.3267\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2077 - mae: 0.3181\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1772 - mae: 0.2981\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2189 - mae: 0.2886\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2851 - mae: 0.2967\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2318 - mae: 0.2939\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2170 - mae: 0.2853\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b9ed3320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4369 - mae: 0.4527\n",
      "processing fold # 3\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 1ms/step - loss: 1.2738 - mae: 0.7879\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.4708 - mae: 0.7930\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8197 - mae: 0.6511\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.8413 - mae: 0.6085\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3908 - mae: 0.4277\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6737 - mae: 0.5652\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.0471 - mae: 0.6484\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7135 - mae: 0.5635\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.9645 - mae: 0.5971\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6237 - mae: 0.5109\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.0228 - mae: 0.6051\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6109 - mae: 0.4947\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5464 - mae: 0.4952\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3723 - mae: 0.4081\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.2001 - mae: 0.6198\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2621 - mae: 0.3819\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.7415 - mae: 0.5550\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3444 - mae: 0.3756\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4014 - mae: 0.3859\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4462 - mae: 0.3966\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3778 - mae: 0.3980\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4404 - mae: 0.4069\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4304 - mae: 0.4451\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3809 - mae: 0.4001\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6367 - mae: 0.4345\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3524 - mae: 0.3811\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3725 - mae: 0.3697\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3830 - mae: 0.4531\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4814 - mae: 0.4136\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4242 - mae: 0.3850\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3749 - mae: 0.3604\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6708 - mae: 0.4687\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5101 - mae: 0.4825\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7490 - mae: 0.4728\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4205 - mae: 0.3928\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3162 - mae: 0.3743\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3644 - mae: 0.4082\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5174 - mae: 0.4035\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6632 - mae: 0.4742\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6064 - mae: 0.4383\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5227 - mae: 0.4705\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3187 - mae: 0.3809\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5321 - mae: 0.4589\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4187 - mae: 0.4238\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5840 - mae: 0.4346\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3558 - mae: 0.3847\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2972 - mae: 0.3954\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4099 - mae: 0.3785\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2659 - mae: 0.3649\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3808 - mae: 0.4002\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2525 - mae: 0.3628\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2522 - mae: 0.2982\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1744 - mae: 0.2604\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3299 - mae: 0.3653\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3841 - mae: 0.4209\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4349 - mae: 0.3823\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2978 - mae: 0.3365\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4084 - mae: 0.3593\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4199 - mae: 0.4086\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2602 - mae: 0.3423\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3859 - mae: 0.4061\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4082 - mae: 0.4204\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5823 - mae: 0.4032\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3836 - mae: 0.4198\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2884 - mae: 0.3198\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2387 - mae: 0.3245\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3679 - mae: 0.3520\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2793 - mae: 0.3134\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.5334 - mae: 0.3912\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4258 - mae: 0.3685\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4323 - mae: 0.3967\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.5791 - mae: 0.4921\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2708 - mae: 0.3502\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6172 - mae: 0.4650\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1741 - mae: 0.2952\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3470 - mae: 0.3751\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2875 - mae: 0.3222\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2035 - mae: 0.3210\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1978 - mae: 0.2914\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2769 - mae: 0.2958\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.6036 - mae: 0.4225\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2576 - mae: 0.2875\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2945 - mae: 0.3251\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3358 - mae: 0.3099\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2873 - mae: 0.3360\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1660 - mae: 0.2733\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2646 - mae: 0.3257\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2454 - mae: 0.2816\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3382 - mae: 0.3445\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4151 - mae: 0.3938\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2420 - mae: 0.3118\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2925 - mae: 0.2941\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.2355 - mae: 0.2809\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2309 - mae: 0.3247\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1874 - mae: 0.2751\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1866 - mae: 0.2697\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.7509 - mae: 0.5415\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2808 - mae: 0.3660\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.3841 - mae: 0.3699\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2435 - mae: 0.2798\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6bceec440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1671 - mae: 0.2976\n"
     ]
    }
   ],
   "source": [
    "#k-fold validtion with dropout\n",
    "import numpy as np\n",
    "k =  4\n",
    "num_val_samples = len(train) // k\n",
    "num_epochs = 100\n",
    "all_scores_drop = []\n",
    "for i in range(k):\n",
    "  print('processing fold #', i)\n",
    "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
    "  # print(partial_train_data)\n",
    "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
    "  model = build_model_drop('relu')\n",
    "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=1)\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
    "  all_scores_drop.append(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSlCIMtT_Gfd"
   },
   "source": [
    "# Scores\n",
    "## here we will see  MAE mean absolute Error scores of all model which we have saved in the list during each training in above section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "We_C7ivQsh8Y",
    "outputId": "27147bd9-2b3a-4976-fa0d-252bdb5e8e4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30838829278945923,\n",
       " 0.33162736892700195,\n",
       " 0.31795740127563477,\n",
       " 0.2738637626171112]"
      ]
     },
     "execution_count": 209,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1gBTB5DrDA9",
    "outputId": "c4e8dc8a-6999-4f43-a60e-87aaf5727a83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32505354285240173,\n",
       " 0.3889753222465515,\n",
       " 0.46358129382133484,\n",
       " 0.3582651913166046]"
      ]
     },
     "execution_count": 210,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zf7O0WnN9bVF",
    "outputId": "32c9623c-1723-4757-87c2-6cffb1d55a8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2906787693500519,\n",
       " 0.2444726675748825,\n",
       " 0.40380221605300903,\n",
       " 0.3436039984226227]"
      ]
     },
     "execution_count": 211,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jB8LxbiI0cpx",
    "outputId": "d0768849-4885-4e42-e4b4-b84b9b9f9b6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5406501889228821,\n",
       " 0.4202413260936737,\n",
       " 0.45266208052635193,\n",
       " 0.29755234718322754]"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNxMnoqoAYd-"
   },
   "source": [
    "# training on the training data\n",
    "## here we will call each model separately from Models section and train on the training data and evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VORrpehRb7UR",
    "outputId": "3d7a5162-c462-4fbb-837e-19e7fcdb6c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6ad955c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1038 - mae: 0.2437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_tanh = build_model('tanh')\n",
    "model_tanh.fit(train, train_l,epochs= 100, batch_size=1, verbose=0)\n",
    "test_mse_score, test_mae_score = model_tanh.evaluate(test, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ttydi9BzUnf5",
    "outputId": "bbbeea4f-7660-4016-a152-a4c566c50370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b5921d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0852 - mae: 0.2275\n"
     ]
    }
   ],
   "source": [
    "model_relu = build_model('relu')\n",
    "model_relu.fit(train, train_l,epochs= 100, batch_size=1, verbose=0)\n",
    "test_mse_score, test_mae_score = model_relu.evaluate(test, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZFYcfHftNlY",
    "outputId": "7b3379dd-a3c7-489c-92dc-2f4d6d198f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6b0d9e9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1397 - mae: 0.2406\n"
     ]
    }
   ],
   "source": [
    "model_regular = build_model_regular('relu')\n",
    "model_regular.fit(train, train_l,epochs= 100, batch_size=1, verbose=0)\n",
    "test_mse_score, test_mae_score = model_regular.evaluate(test, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELSZLSCb0g7c",
    "outputId": "2400eba5-f115-4563-951b-7e57591c3614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa6ad967710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1683 - mae: 0.3534\n"
     ]
    }
   ],
   "source": [
    "model_drop = build_model_drop('relu')\n",
    "model_drop.fit(train, train_l,epochs= 100, batch_size=1, verbose=0)\n",
    "test_mse_score, test_mae_score = model_drop.evaluate(test, test_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV42POJyA-Na"
   },
   "source": [
    "# Prediction Section\n",
    "## here we will predict our prices of our test dataset with each model which we have trained in training section\n",
    "## Note that here we will use the reverse process of Normalization to retrieve our values of price in thousand of dollars i.e. x = (y - mean)/ std ==>> we will calculate( y = x * std + mean) and then we will compare it with our target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5QU9eNHg5_b",
    "outputId": "31fcfc8a-6ea9-4c0a-9095-079dacb87f4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01414832,  0.3725343 ,  1.3658801 ,  2.122337  , -1.004718  ,\n",
       "       -0.7045773 , -0.5886972 , -0.97443527, -0.763189  , -0.52312535,\n",
       "       -0.05301089, -0.3704908 , -0.5449216 , -0.80397296, -0.5536523 ,\n",
       "       -0.26059392,  0.6062484 ,  1.4864004 ,  2.5404336 ,  3.367835  ,\n",
       "       -0.8779702 , -0.09159691,  0.18192424, -0.7802841 , -0.50065756,\n",
       "       -0.9622245 , -0.6813769 , -0.5409531 ,  0.01463675,  0.12453365,\n",
       "        0.46643507, -0.1806134 ,  0.2687428 ,  0.4299249 ,  0.45129374,\n",
       "       -0.07511237,  2.3382235 ,  2.200547  , -0.49870384,  0.20280465,\n",
       "        0.26019526, -0.68430746, -0.7224051 , -0.65524584, -0.98066276,\n",
       "       -0.7889537 , -0.7547636 , -0.6888255 , -0.6277716 , -0.4983375 ,\n",
       "       -0.6020069 , -0.4139611 , -0.22347318, -0.54107517,  0.28217462,\n",
       "       -0.68430746, -0.6574438 , -0.59638995, -0.01027321,  0.056886  ,\n",
       "       -0.1329914 , -0.05362143,  0.3181964 ,  0.6155285 ], dtype=float32)"
      ]
     },
     "execution_count": 217,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "mua_UYVJ7YNd"
   },
   "outputs": [],
   "source": [
    "def predict(model, m):\n",
    "  print(f\" the Actual value Price was : {test_l[m]* std_label + mean_label} \" )\n",
    "  return(f\" the predicted Price was : {(model.predict(test[m:m+1].reshape(1,test.shape[1]))) * std_label + mean_label} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "ofX9VqMVbhBC",
    "outputId": "670abf77-949d-422b-e6e2-4d3527bf1ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the Actual value Price was : 24565.000309357743 \n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa6b9eed560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' the predicted Price was : [[19511.]] '"
      ]
     },
     "execution_count": 219,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tanh = predict(model_tanh,2)\n",
    "x_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "4Z0UyL_LOImw",
    "outputId": "bf7c9059-ff55-48f0-b0e3-0cab32005c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the Actual value Price was : 24565.000309357743 \n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa6bcfc2560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' the predicted Price was : [[21036.79]] '"
      ]
     },
     "execution_count": 220,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_relu = predict(model_relu,2)\n",
    "x_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "nlQRNOo0tb8J",
    "outputId": "62ce4e74-0d8e-4d13-946f-b6251e6314e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the Actual value Price was : 24565.000309357743 \n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa6aa28f200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' the predicted Price was : [[23140.42]] '"
      ]
     },
     "execution_count": 221,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_regular = predict(model_regular,2)\n",
    "x_regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "uW5Y65pP0qET",
    "outputId": "3428f362-cea1-4219-9843-928105cf1fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the Actual value Price was : 24565.000309357743 \n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa6aa2a0ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' the predicted Price was : [[22173.531]] '"
      ]
     },
     "execution_count": 222,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_drop = predict(model_drop,2)\n",
    "x_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "pYpye06_xzjc"
   },
   "outputs": [],
   "source": [
    "def plot_fn(mod):\n",
    "  y_true = test_l* std_label + mean_label\n",
    "  y_pred = mod.predict(test) * std_label + mean_label\n",
    "  return y_true , y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "leNMnlxfx5nt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plotting(mod, label):\n",
    "  y_true, y_pred = plot_fn(mod)\n",
    "  coef = np.polyfit(y_true,y_pred,1)\n",
    "  poly1d_fn = np.poly1d(coef) \n",
    "  # poly1d_fn is now a function which takes in x and returns an estimate for y\n",
    "  plt.figure()\n",
    "  plt.plot(y_true,y_pred, 'yo', y_true, poly1d_fn(y_true), '--k')\n",
    "  plt.title(label)\n",
    "  plt.xlabel('Thousand Dollar True' )\n",
    "  plt.ylabel('Thousand Dollar Predictions' )\n",
    "  plt.xlim(0, 50000)\n",
    "  plt.ylim(0, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3rQG1a79x72V",
    "outputId": "4d95f3da-c02f-49de-a897-21422cc9d507"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_list = []\n",
    "for i,j in enumerate([model_relu, model_tanh, model_regular, model_drop]):\n",
    "  list_name = ['model_relu', 'model_tanh', 'model_regular', 'model_drop']\n",
    "  plot_list.append(plotting(j,list_name[i]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Car_Price_Prediction_assignment_final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
