{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1901,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.5'"
      ]
     },
     "execution_count": 1902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.4'"
      ]
     },
     "execution_count": 1903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "df = pd.read_csv('ionosphere_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 1905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape of the dataset \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from the shape of the data that dataset is not a huge one. Only 351 records are available with 34 features/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1906,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 1906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>0.87111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature7</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>0.72873</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature8</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature9</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>0.68421</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature10</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature11</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.66798</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature12</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.065265</td>\n",
       "      <td>0.02825</td>\n",
       "      <td>0.482375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature13</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.400801</td>\n",
       "      <td>0.622186</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.64407</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.073725</td>\n",
       "      <td>0.03027</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature15</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.344159</td>\n",
       "      <td>0.652828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60194</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature16</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.081705</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature17</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.381949</td>\n",
       "      <td>0.618020</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.59091</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature18</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.496762</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.225690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature19</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.359390</td>\n",
       "      <td>0.626267</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57619</td>\n",
       "      <td>0.899265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature20</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>0.519076</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.234670</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.134370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature21</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.609828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49909</td>\n",
       "      <td>0.894865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature22</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.518166</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.243870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature23</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.362475</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.53176</td>\n",
       "      <td>0.911235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature24</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.057406</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.366885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature25</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.55389</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature26</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>-0.01505</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature27</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>0.70824</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature28</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>-0.01769</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature29</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49664</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature30</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature31</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.44277</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature32</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature33</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40956</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature34</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std  min       25%      50%       75%  max\n",
       "feature1   351.0  0.891738  0.311155  0.0  1.000000  1.00000  1.000000  1.0\n",
       "feature2   351.0  0.000000  0.000000  0.0  0.000000  0.00000  0.000000  0.0\n",
       "feature3   351.0  0.641342  0.497708 -1.0  0.472135  0.87111  1.000000  1.0\n",
       "feature4   351.0  0.044372  0.441435 -1.0 -0.064735  0.01631  0.194185  1.0\n",
       "feature5   351.0  0.601068  0.519862 -1.0  0.412660  0.80920  1.000000  1.0\n",
       "feature6   351.0  0.115889  0.460810 -1.0 -0.024795  0.02280  0.334655  1.0\n",
       "feature7   351.0  0.550095  0.492654 -1.0  0.211310  0.72873  0.969240  1.0\n",
       "feature8   351.0  0.119360  0.520750 -1.0 -0.054840  0.01471  0.445675  1.0\n",
       "feature9   351.0  0.511848  0.507066 -1.0  0.087110  0.68421  0.953240  1.0\n",
       "feature10  351.0  0.181345  0.483851 -1.0 -0.048075  0.01829  0.534195  1.0\n",
       "feature11  351.0  0.476183  0.563496 -1.0  0.021120  0.66798  0.957895  1.0\n",
       "feature12  351.0  0.155040  0.494817 -1.0 -0.065265  0.02825  0.482375  1.0\n",
       "feature13  351.0  0.400801  0.622186 -1.0  0.000000  0.64407  0.955505  1.0\n",
       "feature14  351.0  0.093414  0.494873 -1.0 -0.073725  0.03027  0.374860  1.0\n",
       "feature15  351.0  0.344159  0.652828 -1.0  0.000000  0.60194  0.919330  1.0\n",
       "feature16  351.0  0.071132  0.458371 -1.0 -0.081705  0.00000  0.308975  1.0\n",
       "feature17  351.0  0.381949  0.618020 -1.0  0.000000  0.59091  0.935705  1.0\n",
       "feature18  351.0 -0.003617  0.496762 -1.0 -0.225690  0.00000  0.195285  1.0\n",
       "feature19  351.0  0.359390  0.626267 -1.0  0.000000  0.57619  0.899265  1.0\n",
       "feature20  351.0 -0.024025  0.519076 -1.0 -0.234670  0.00000  0.134370  1.0\n",
       "feature21  351.0  0.336695  0.609828 -1.0  0.000000  0.49909  0.894865  1.0\n",
       "feature22  351.0  0.008296  0.518166 -1.0 -0.243870  0.00000  0.188760  1.0\n",
       "feature23  351.0  0.362475  0.603767 -1.0  0.000000  0.53176  0.911235  1.0\n",
       "feature24  351.0 -0.057406  0.527456 -1.0 -0.366885  0.00000  0.164630  1.0\n",
       "feature25  351.0  0.396135  0.578451 -1.0  0.000000  0.55389  0.905240  1.0\n",
       "feature26  351.0 -0.071187  0.508495 -1.0 -0.332390 -0.01505  0.156765  1.0\n",
       "feature27  351.0  0.541641  0.516205 -1.0  0.286435  0.70824  0.999945  1.0\n",
       "feature28  351.0 -0.069538  0.550025 -1.0 -0.443165 -0.01769  0.153535  1.0\n",
       "feature29  351.0  0.378445  0.575886 -1.0  0.000000  0.49664  0.883465  1.0\n",
       "feature30  351.0 -0.027907  0.507974 -1.0 -0.236885  0.00000  0.154075  1.0\n",
       "feature31  351.0  0.352514  0.571483 -1.0  0.000000  0.44277  0.857620  1.0\n",
       "feature32  351.0 -0.003794  0.513574 -1.0 -0.242595  0.00000  0.200120  1.0\n",
       "feature33  351.0  0.349364  0.522663 -1.0  0.000000  0.40956  0.813765  1.0\n",
       "feature34  351.0  0.014480  0.468337 -1.0 -0.165350  0.00000  0.171660  1.0"
      ]
     },
     "execution_count": 1907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1\n",
      "2\n",
      "feature2\n",
      "1\n",
      "feature3\n",
      "219\n",
      "feature4\n",
      "269\n",
      "feature5\n",
      "204\n",
      "feature6\n",
      "259\n",
      "feature7\n",
      "231\n",
      "feature8\n",
      "260\n",
      "feature9\n",
      "244\n",
      "feature10\n",
      "267\n",
      "feature11\n",
      "246\n",
      "feature12\n",
      "269\n",
      "feature13\n",
      "238\n",
      "feature14\n",
      "266\n",
      "feature15\n",
      "234\n",
      "feature16\n",
      "270\n",
      "feature17\n",
      "254\n",
      "feature18\n",
      "280\n",
      "feature19\n",
      "254\n",
      "feature20\n",
      "266\n",
      "feature21\n",
      "248\n",
      "feature22\n",
      "265\n",
      "feature23\n",
      "248\n",
      "feature24\n",
      "264\n",
      "feature25\n",
      "256\n",
      "feature26\n",
      "273\n",
      "feature27\n",
      "256\n",
      "feature28\n",
      "281\n",
      "feature29\n",
      "244\n",
      "feature30\n",
      "266\n",
      "feature31\n",
      "243\n",
      "feature32\n",
      "263\n",
      "feature33\n",
      "245\n",
      "feature34\n",
      "263\n",
      "label\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for feature in df:\n",
    "    print(feature)\n",
    "    print(len(df[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 1909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[1], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "0         1   0.99539  -0.05889   0.85243   0.02306   0.83398  -0.37708   \n",
       "1         1   1.00000  -0.18829   0.93035  -0.36156  -0.10868  -0.93597   \n",
       "2         1   1.00000  -0.03365   1.00000   0.00485   1.00000  -0.12062   \n",
       "3         1   1.00000  -0.45161   1.00000   1.00000   0.71216  -1.00000   \n",
       "4         1   1.00000  -0.02401   0.94140   0.06531   0.92106  -0.23255   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature26  feature27  feature28  \\\n",
       "0   1.00000    0.03760    0.85243  ...   -0.51171    0.41078   -0.46168   \n",
       "1   1.00000   -0.04549    0.50874  ...   -0.26569   -0.20468   -0.18401   \n",
       "2   0.88965    0.01198    0.73082  ...   -0.40220    0.58984   -0.22145   \n",
       "3   0.00000    0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4   0.77152   -0.16399    0.52798  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1913,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 34 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature3   351 non-null    float64\n",
      " 2   feature4   351 non-null    float64\n",
      " 3   feature5   351 non-null    float64\n",
      " 4   feature6   351 non-null    float64\n",
      " 5   feature7   351 non-null    float64\n",
      " 6   feature8   351 non-null    float64\n",
      " 7   feature9   351 non-null    float64\n",
      " 8   feature10  351 non-null    float64\n",
      " 9   feature11  351 non-null    float64\n",
      " 10  feature12  351 non-null    float64\n",
      " 11  feature13  351 non-null    float64\n",
      " 12  feature14  351 non-null    float64\n",
      " 13  feature15  351 non-null    float64\n",
      " 14  feature16  351 non-null    float64\n",
      " 15  feature17  351 non-null    float64\n",
      " 16  feature18  351 non-null    float64\n",
      " 17  feature19  351 non-null    float64\n",
      " 18  feature20  351 non-null    float64\n",
      " 19  feature21  351 non-null    float64\n",
      " 20  feature22  351 non-null    float64\n",
      " 21  feature23  351 non-null    float64\n",
      " 22  feature24  351 non-null    float64\n",
      " 23  feature25  351 non-null    float64\n",
      " 24  feature26  351 non-null    float64\n",
      " 25  feature27  351 non-null    float64\n",
      " 26  feature28  351 non-null    float64\n",
      " 27  feature29  351 non-null    float64\n",
      " 28  feature30  351 non-null    float64\n",
      " 29  feature31  351 non-null    float64\n",
      " 30  feature32  351 non-null    float64\n",
      " 31  feature33  351 non-null    float64\n",
      " 32  feature34  351 non-null    float64\n",
      " 33  label      351 non-null    object \n",
      "dtypes: float64(32), int64(1), object(1)\n",
      "memory usage: 93.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for feature in df:\\n    print(feature)\\n    df[feature].hist()\\n    plt.show()'"
      ]
     },
     "execution_count": 1914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for feature in df:\n",
    "    print(feature)\n",
    "    df[feature].hist()\n",
    "    plt.show()'''\n",
    "\n",
    "# df.hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.641342    0.044372    0.601068    0.115889    0.550095   \n",
       "std      0.311155    0.497708    0.441435    0.519862    0.460810    0.492654   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.472135   -0.064735    0.412660   -0.024795    0.211310   \n",
       "50%      1.000000    0.871110    0.016310    0.809200    0.022800    0.728730   \n",
       "75%      1.000000    1.000000    0.194185    1.000000    0.334655    0.969240   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.119360    0.511848    0.181345    0.476183  ...    0.396135   \n",
       "std      0.520750    0.507066    0.483851    0.563496  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.054840    0.087110   -0.048075    0.021120  ...    0.000000   \n",
       "50%      0.014710    0.684210    0.018290    0.667980  ...    0.553890   \n",
       "75%      0.445675    0.953240    0.534195    0.957895  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 1915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1916,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [1 if lbl == 'g' else 0 for lbl in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.sample(frac= 0.6, random_state=125)\n",
    "test_data = df.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.iloc[:,-1]\n",
    "train_data = train_data.iloc[:,0:-1]\n",
    "test_label = test_data.iloc[:,-1]\n",
    "test_data = test_data.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns= 'label', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.96775</td>\n",
       "      <td>-0.00482</td>\n",
       "      <td>0.96683</td>\n",
       "      <td>-0.00722</td>\n",
       "      <td>0.87980</td>\n",
       "      <td>-0.03923</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.02003</td>\n",
       "      <td>0.93772</td>\n",
       "      <td>-0.03034</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05843</td>\n",
       "      <td>0.92774</td>\n",
       "      <td>-0.03464</td>\n",
       "      <td>0.92226</td>\n",
       "      <td>-0.03673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14754</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.04918</td>\n",
       "      <td>0.57377</td>\n",
       "      <td>-0.01639</td>\n",
       "      <td>0.65574</td>\n",
       "      <td>0.01639</td>\n",
       "      <td>0.85246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31148</td>\n",
       "      <td>-0.34426</td>\n",
       "      <td>0.52385</td>\n",
       "      <td>-0.20325</td>\n",
       "      <td>0.32787</td>\n",
       "      <td>-0.03279</td>\n",
       "      <td>0.27869</td>\n",
       "      <td>-0.44262</td>\n",
       "      <td>0.49180</td>\n",
       "      <td>-0.06557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89706</td>\n",
       "      <td>0.38235</td>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.74265</td>\n",
       "      <td>0.67647</td>\n",
       "      <td>0.45588</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>0.19118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74265</td>\n",
       "      <td>-0.12500</td>\n",
       "      <td>-0.67925</td>\n",
       "      <td>-0.24131</td>\n",
       "      <td>-0.55147</td>\n",
       "      <td>-0.42647</td>\n",
       "      <td>-0.44118</td>\n",
       "      <td>-0.50735</td>\n",
       "      <td>-0.28676</td>\n",
       "      <td>-0.56618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84557</td>\n",
       "      <td>-0.08580</td>\n",
       "      <td>-0.31745</td>\n",
       "      <td>-0.80553</td>\n",
       "      <td>-0.08961</td>\n",
       "      <td>-0.56435</td>\n",
       "      <td>0.80648</td>\n",
       "      <td>0.04576</td>\n",
       "      <td>0.89514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78932</td>\n",
       "      <td>-0.03718</td>\n",
       "      <td>0.70882</td>\n",
       "      <td>-0.25288</td>\n",
       "      <td>0.77884</td>\n",
       "      <td>-0.14109</td>\n",
       "      <td>-0.21354</td>\n",
       "      <td>-0.78170</td>\n",
       "      <td>-0.18494</td>\n",
       "      <td>-0.59867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>-0.99265</td>\n",
       "      <td>0.80882</td>\n",
       "      <td>0.55147</td>\n",
       "      <td>-0.41912</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "270         1   1.00000   0.08013   0.96775  -0.00482   0.96683  -0.00722   \n",
       "116         1   1.00000  -0.14754   1.00000   0.04918   0.57377  -0.01639   \n",
       "135         1   0.89706   0.38235   0.91176   0.37500   0.74265   0.67647   \n",
       "91          1   0.84557  -0.08580  -0.31745  -0.80553  -0.08961  -0.56435   \n",
       "100         1   1.00000  -1.00000   0.00000   0.00000   0.77941  -0.99265   \n",
       "\n",
       "     feature9  feature10  feature11  ...  feature25  feature26  feature27  \\\n",
       "270   0.87980   -0.03923    1.00000  ...    0.98164    0.02003    0.93772   \n",
       "116   0.65574    0.01639    0.85246  ...    0.31148   -0.34426    0.52385   \n",
       "135   0.45588    0.77941    0.19118  ...   -0.74265   -0.12500   -0.67925   \n",
       "91    0.80648    0.04576    0.89514  ...    0.78932   -0.03718    0.70882   \n",
       "100   0.80882    0.55147   -0.41912  ...   -1.00000   -1.00000   -1.00000   \n",
       "\n",
       "     feature28  feature29  feature30  feature31  feature32  feature33  \\\n",
       "270   -0.03034    1.00000   -0.05843    0.92774   -0.03464    0.92226   \n",
       "116   -0.20325    0.32787   -0.03279    0.27869   -0.44262    0.49180   \n",
       "135   -0.24131   -0.55147   -0.42647   -0.44118   -0.50735   -0.28676   \n",
       "91    -0.25288    0.77884   -0.14109   -0.21354   -0.78170   -0.18494   \n",
       "100   -1.00000    1.00000   -1.00000    1.00000   -1.00000    0.00000   \n",
       "\n",
       "     feature34  \n",
       "270   -0.03673  \n",
       "116   -0.06557  \n",
       "135   -0.56618  \n",
       "91    -0.59867  \n",
       "100    0.00000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 1921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270    1\n",
       "116    0\n",
       "135    1\n",
       "91     0\n",
       "100    0\n",
       "      ..\n",
       "213    1\n",
       "161    1\n",
       "141    1\n",
       "59     0\n",
       "113    1\n",
       "Name: label, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 1922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardized the Input Variables. **Hint**: Centeralized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "# train_mean = train_data.mean()\n",
    "# train_data -= train_mean\n",
    "# train_std = train_data.std()\n",
    "# train_data /= train_std\n",
    "# test_data -= train_mean\n",
    "# test_data /= train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle the data if needed.\n",
    "- Split into 60 and 40 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sample the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 33)"
      ]
     },
     "execution_count": 1925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 33)"
      ]
     },
     "execution_count": 1926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,)"
      ]
     },
     "execution_count": 1927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 1928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 1929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 1930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1931,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label.sum()/len(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1936,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = np.array(train_set.as_matrix())\n",
    "#train_label = np.array(pd.DataFrame(train_label).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1937,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(train_label))\n",
    "print(type(test_data))\n",
    "print(type(test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n",
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtype)\n",
    "print(train_label.dtype)\n",
    "print(test_label.dtype)\n",
    "print(test_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model : 1 hidden layers including 16 unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1939,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,  activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 128)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1941,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer = 'RMSprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the Model with Epochs (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1942,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "5/5 [==============================] - 1s 66ms/step - loss: 0.6412 - accuracy: 0.6187 - val_loss: 0.5181 - val_accuracy: 0.7925\n",
      "Epoch 2/75\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5304 - accuracy: 0.8127 - val_loss: 0.4738 - val_accuracy: 0.8302\n",
      "Epoch 3/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5007 - accuracy: 0.7915 - val_loss: 0.4405 - val_accuracy: 0.8679\n",
      "Epoch 4/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4766 - accuracy: 0.8221 - val_loss: 0.4160 - val_accuracy: 0.8491\n",
      "Epoch 5/75\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4203 - accuracy: 0.8504 - val_loss: 0.3884 - val_accuracy: 0.8868\n",
      "Epoch 6/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4194 - accuracy: 0.8170 - val_loss: 0.3626 - val_accuracy: 0.9057\n",
      "Epoch 7/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3825 - accuracy: 0.8641 - val_loss: 0.3398 - val_accuracy: 0.9245\n",
      "Epoch 8/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3389 - accuracy: 0.9137 - val_loss: 0.3202 - val_accuracy: 0.9057\n",
      "Epoch 9/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3205 - accuracy: 0.8960 - val_loss: 0.3023 - val_accuracy: 0.9434\n",
      "Epoch 10/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2848 - accuracy: 0.9322 - val_loss: 0.2846 - val_accuracy: 0.9623\n",
      "Epoch 11/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2688 - accuracy: 0.9331 - val_loss: 0.2749 - val_accuracy: 0.9623\n",
      "Epoch 12/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2784 - accuracy: 0.9216 - val_loss: 0.2587 - val_accuracy: 0.9623\n",
      "Epoch 13/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2378 - accuracy: 0.9477 - val_loss: 0.2468 - val_accuracy: 0.9623\n",
      "Epoch 14/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2198 - accuracy: 0.9514 - val_loss: 0.2350 - val_accuracy: 0.9623\n",
      "Epoch 15/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1958 - accuracy: 0.9678 - val_loss: 0.2273 - val_accuracy: 0.9623\n",
      "Epoch 16/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1961 - accuracy: 0.9413 - val_loss: 0.2217 - val_accuracy: 0.9623\n",
      "Epoch 17/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1864 - accuracy: 0.9343 - val_loss: 0.2174 - val_accuracy: 0.9623\n",
      "Epoch 18/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1686 - accuracy: 0.9501 - val_loss: 0.2157 - val_accuracy: 0.9623\n",
      "Epoch 19/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1731 - accuracy: 0.9661 - val_loss: 0.2123 - val_accuracy: 0.9623\n",
      "Epoch 20/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1603 - accuracy: 0.9558 - val_loss: 0.2083 - val_accuracy: 0.9623\n",
      "Epoch 21/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1552 - accuracy: 0.9419 - val_loss: 0.2012 - val_accuracy: 0.9623\n",
      "Epoch 22/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1240 - accuracy: 0.9651 - val_loss: 0.1986 - val_accuracy: 0.9623\n",
      "Epoch 23/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1510 - accuracy: 0.9471 - val_loss: 0.1950 - val_accuracy: 0.9623\n",
      "Epoch 24/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1569 - accuracy: 0.9341 - val_loss: 0.1970 - val_accuracy: 0.9623\n",
      "Epoch 25/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1167 - accuracy: 0.9726 - val_loss: 0.1959 - val_accuracy: 0.9623\n",
      "Epoch 26/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1326 - accuracy: 0.9652 - val_loss: 0.1941 - val_accuracy: 0.9623\n",
      "Epoch 27/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1445 - accuracy: 0.9474 - val_loss: 0.1998 - val_accuracy: 0.9623\n",
      "Epoch 28/75\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1011 - accuracy: 0.9850 - val_loss: 0.1994 - val_accuracy: 0.9623\n",
      "Epoch 29/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1197 - accuracy: 0.9645 - val_loss: 0.2033 - val_accuracy: 0.9623\n",
      "Epoch 30/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1122 - accuracy: 0.9461 - val_loss: 0.1991 - val_accuracy: 0.9623\n",
      "Epoch 31/75\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1217 - accuracy: 0.9781 - val_loss: 0.2017 - val_accuracy: 0.9623\n",
      "Epoch 32/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0883 - accuracy: 0.9793 - val_loss: 0.1978 - val_accuracy: 0.9623\n",
      "Epoch 33/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1038 - accuracy: 0.9850 - val_loss: 0.2052 - val_accuracy: 0.9623\n",
      "Epoch 34/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1112 - accuracy: 0.9491 - val_loss: 0.1982 - val_accuracy: 0.9623\n",
      "Epoch 35/75\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0846 - accuracy: 0.9767 - val_loss: 0.2098 - val_accuracy: 0.9623\n",
      "Epoch 36/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0777 - accuracy: 0.9746 - val_loss: 0.1973 - val_accuracy: 0.9623\n",
      "Epoch 37/75\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0794 - accuracy: 0.9720 - val_loss: 0.2055 - val_accuracy: 0.9623\n",
      "Epoch 38/75\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0803 - accuracy: 0.9668 - val_loss: 0.2197 - val_accuracy: 0.9623\n",
      "Epoch 39/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0700 - accuracy: 0.9793 - val_loss: 0.2164 - val_accuracy: 0.9623\n",
      "Epoch 40/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0854 - accuracy: 0.9738 - val_loss: 0.2144 - val_accuracy: 0.9623\n",
      "Epoch 41/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0648 - accuracy: 0.9863 - val_loss: 0.2030 - val_accuracy: 0.9623\n",
      "Epoch 42/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0696 - accuracy: 0.9747 - val_loss: 0.2098 - val_accuracy: 0.9623\n",
      "Epoch 43/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0365 - accuracy: 0.9932 - val_loss: 0.2065 - val_accuracy: 0.9623\n",
      "Epoch 44/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0560 - accuracy: 0.9863 - val_loss: 0.2170 - val_accuracy: 0.9623\n",
      "Epoch 45/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0594 - accuracy: 0.9689 - val_loss: 0.2229 - val_accuracy: 0.9623\n",
      "Epoch 46/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0435 - accuracy: 0.9898 - val_loss: 0.2159 - val_accuracy: 0.9434\n",
      "Epoch 47/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0442 - accuracy: 0.9945 - val_loss: 0.2114 - val_accuracy: 0.9434\n",
      "Epoch 48/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0430 - accuracy: 0.9922 - val_loss: 0.2133 - val_accuracy: 0.9623\n",
      "Epoch 49/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0696 - accuracy: 0.9590 - val_loss: 0.2099 - val_accuracy: 0.9434\n",
      "Epoch 50/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0536 - accuracy: 0.9819 - val_loss: 0.2126 - val_accuracy: 0.9434\n",
      "Epoch 51/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0285 - accuracy: 0.9966 - val_loss: 0.2119 - val_accuracy: 0.9434\n",
      "Epoch 52/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0431 - accuracy: 0.9836 - val_loss: 0.2155 - val_accuracy: 0.9623\n",
      "Epoch 53/75\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0529 - accuracy: 0.9793 - val_loss: 0.2185 - val_accuracy: 0.9623\n",
      "Epoch 54/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 0.2165 - val_accuracy: 0.9434\n",
      "Epoch 55/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0448 - accuracy: 0.9836 - val_loss: 0.2148 - val_accuracy: 0.9434\n",
      "Epoch 56/75\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0310 - accuracy: 0.9966 - val_loss: 0.2175 - val_accuracy: 0.9434\n",
      "Epoch 57/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9623\n",
      "Epoch 58/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.2247 - val_accuracy: 0.9434\n",
      "Epoch 59/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0269 - accuracy: 0.9979 - val_loss: 0.2268 - val_accuracy: 0.9434\n",
      "Epoch 60/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0352 - accuracy: 0.9849 - val_loss: 0.2328 - val_accuracy: 0.9434\n",
      "Epoch 61/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0233 - accuracy: 0.9966 - val_loss: 0.2380 - val_accuracy: 0.9434\n",
      "Epoch 62/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0162 - accuracy: 0.9979 - val_loss: 0.2337 - val_accuracy: 0.9434\n",
      "Epoch 63/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0278 - accuracy: 0.9949 - val_loss: 0.2416 - val_accuracy: 0.9623\n",
      "Epoch 64/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0218 - accuracy: 0.9966 - val_loss: 0.2410 - val_accuracy: 0.9623\n",
      "Epoch 65/75\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9434\n",
      "Epoch 66/75\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0140 - accuracy: 0.9922 - val_loss: 0.2551 - val_accuracy: 0.9623\n",
      "Epoch 67/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9623\n",
      "Epoch 68/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.2720 - val_accuracy: 0.9623\n",
      "Epoch 69/75\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0202 - accuracy: 0.9949 - val_loss: 0.2740 - val_accuracy: 0.9623\n",
      "Epoch 70/75\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0235 - accuracy: 0.9888 - val_loss: 0.2654 - val_accuracy: 0.9434\n",
      "Epoch 71/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9623\n",
      "Epoch 72/75\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9623\n",
      "Epoch 73/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9623\n",
      "Epoch 74/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.2815 - val_accuracy: 0.9434\n",
      "Epoch 75/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, validation_split=0.25, epochs= 75, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1943,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 1943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1944,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(75)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1945,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation Step\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.9286\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2785840928554535, 0.9285714030265808]"
      ]
     },
     "execution_count": 1947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1948,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1949,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1950,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[46,  9],\n",
       "       [ 1, 84]])>"
      ]
     },
     "execution_count": 1950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(\n",
    "    test_label, y_pred, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1951,
   "metadata": {},
   "outputs": [],
   "source": [
    " # It will evaluate the logical expression y_predict>0.25 and return True or False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 1952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
